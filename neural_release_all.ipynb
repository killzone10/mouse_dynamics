{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.consts import * ## const variables are there, so paths and extraction features ##\n",
    "from utils. plotting import * ## plotting ##\n",
    "from data_reader_babalit import * ## the class which reads balabit dataset ##\n",
    "from data_reader_chaoshen import * ## the class which reads chaoshen datasets TODO There are several issues with this dataset -> explained later ##\n",
    "from legality_analyser import * ## the class which analyses the datasets with 0 1 labels --> splitting samples is being done there ##  \n",
    "import random\n",
    "from nonlegality_analyser import * ## the class which analyses the datasets without 0 1 labels --> splitting samples is being done there ##  \n",
    "\n",
    "\n",
    "from custom_dataset import *\n",
    "from VAEmodel import *\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "from torch.utils.data import  DataLoader\n",
    "from torchvision import transforms\n",
    "from neural_data_creator import *\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exist\n",
      "type_of_action     1     3     4\n",
      "userid                          \n",
      "7               3885  4090   695\n",
      "9               2473  2580   288\n",
      "12              8350  4561   874\n",
      "15              3332  4796   639\n",
      "16              5231  6681  1450\n",
      "20              3297  2723   333\n",
      "21              3383  3161   528\n",
      "23              2519  3927   307\n",
      "29              2683  4871   938\n",
      "35              2927  2401   380\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Specyfing the USERS ## \n",
    "users = [7,9,12,15,16,20,21,23,29, 35]\n",
    "## Creating the object which analyses the dataset ## \n",
    "balabit_reader = DataReaderBalabit(BALABIT, users, False) ## the arguments are DATASET, users, supervised, how many records should be procesed ##\n",
    "balabit_reader.processDataWithoutLabels() ## creating the data without labels ##\n",
    "## getting path from the reader ##\n",
    "path = balabit_reader.getFileName()\n",
    "\n",
    "## creating analyser class ## \n",
    "balabitAnalyser = nonLegalityAnalyser(path)\n",
    "## counting how many actions were extracted ## \n",
    "print(balabitAnalyser.countActions())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_final = {}\n",
    "precision_final= {}\n",
    "recall_final   = {}\n",
    "f1_final = {}\n",
    "mcc_final= {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Training Loss: 52.7410, Validation Loss: 113.2240\n",
      "Epoch [2/100], Training Loss: 34.7148, Validation Loss: 81.2177\n",
      "Epoch [3/100], Training Loss: 24.8681, Validation Loss: 58.0035\n",
      "Epoch [4/100], Training Loss: 18.9643, Validation Loss: 43.1732\n",
      "Epoch [5/100], Training Loss: 11.5521, Validation Loss: 36.6422\n",
      "Epoch [6/100], Training Loss: 16.4522, Validation Loss: 33.9157\n",
      "Epoch [7/100], Training Loss: 11.6571, Validation Loss: 32.2326\n",
      "Epoch [8/100], Training Loss: 12.0599, Validation Loss: 30.9948\n",
      "Epoch [9/100], Training Loss: 12.2028, Validation Loss: 29.8918\n",
      "Epoch [10/100], Training Loss: 11.2136, Validation Loss: 28.6544\n",
      "Epoch [11/100], Training Loss: 11.0995, Validation Loss: 27.9495\n",
      "Epoch [12/100], Training Loss: 9.9367, Validation Loss: 27.0511\n",
      "Epoch [13/100], Training Loss: 7.6093, Validation Loss: 26.7078\n",
      "Epoch [14/100], Training Loss: 12.3271, Validation Loss: 26.3467\n",
      "Epoch [15/100], Training Loss: 10.5608, Validation Loss: 25.9805\n",
      "Epoch [16/100], Training Loss: 7.1332, Validation Loss: 25.5072\n",
      "Epoch [17/100], Training Loss: 8.6509, Validation Loss: 25.3788\n",
      "Epoch [18/100], Training Loss: 8.5047, Validation Loss: 25.0691\n",
      "Epoch [19/100], Training Loss: 7.7375, Validation Loss: 24.9506\n",
      "Epoch [20/100], Training Loss: 8.1581, Validation Loss: 24.7367\n",
      "Epoch [21/100], Training Loss: 7.5030, Validation Loss: 24.6314\n",
      "Epoch [22/100], Training Loss: 9.1641, Validation Loss: 24.3574\n",
      "Epoch [23/100], Training Loss: 8.3605, Validation Loss: 24.1654\n",
      "Epoch [24/100], Training Loss: 7.8902, Validation Loss: 24.0252\n",
      "Epoch [25/100], Training Loss: 8.2276, Validation Loss: 23.9239\n",
      "Epoch [26/100], Training Loss: 7.5620, Validation Loss: 23.7293\n",
      "Epoch [27/100], Training Loss: 8.4915, Validation Loss: 23.5253\n",
      "Epoch [28/100], Training Loss: 8.0481, Validation Loss: 23.3912\n",
      "Epoch [29/100], Training Loss: 5.8796, Validation Loss: 23.3165\n",
      "Epoch [30/100], Training Loss: 7.4786, Validation Loss: 23.1662\n",
      "Epoch [31/100], Training Loss: 7.5388, Validation Loss: 23.1478\n",
      "Epoch [32/100], Training Loss: 5.9785, Validation Loss: 23.0050\n",
      "Epoch [33/100], Training Loss: 7.9583, Validation Loss: 22.9568\n",
      "Epoch [34/100], Training Loss: 6.9952, Validation Loss: 22.7936\n",
      "Epoch [35/100], Training Loss: 5.9605, Validation Loss: 22.7622\n",
      "Epoch [36/100], Training Loss: 7.0584, Validation Loss: 22.5793\n",
      "Epoch [37/100], Training Loss: 7.0176, Validation Loss: 22.4580\n",
      "Epoch [38/100], Training Loss: 8.2460, Validation Loss: 22.4130\n",
      "Epoch [39/100], Training Loss: 8.8324, Validation Loss: 22.3108\n",
      "Epoch [40/100], Training Loss: 6.9892, Validation Loss: 22.2728\n",
      "Epoch [41/100], Training Loss: 8.0825, Validation Loss: 22.1395\n",
      "Epoch [42/100], Training Loss: 5.8013, Validation Loss: 22.0700\n",
      "Epoch [43/100], Training Loss: 6.1887, Validation Loss: 21.9936\n",
      "Epoch [44/100], Training Loss: 7.8751, Validation Loss: 22.0043\n",
      "Epoch [45/100], Training Loss: 6.9179, Validation Loss: 21.8382\n",
      "Epoch [46/100], Training Loss: 7.0885, Validation Loss: 21.8058\n",
      "Epoch [47/100], Training Loss: 8.9632, Validation Loss: 21.8146\n",
      "Epoch [48/100], Training Loss: 6.8827, Validation Loss: 21.7390\n",
      "Epoch [49/100], Training Loss: 7.3418, Validation Loss: 21.7487\n",
      "Epoch [50/100], Training Loss: 8.4722, Validation Loss: 21.6780\n",
      "Epoch [51/100], Training Loss: 5.7711, Validation Loss: 21.6187\n",
      "Epoch [52/100], Training Loss: 7.6738, Validation Loss: 21.5478\n",
      "Epoch [53/100], Training Loss: 5.7647, Validation Loss: 21.4923\n",
      "Epoch [54/100], Training Loss: 6.7512, Validation Loss: 21.4552\n",
      "Epoch [55/100], Training Loss: 6.6800, Validation Loss: 21.4675\n",
      "Epoch [56/100], Training Loss: 7.6788, Validation Loss: 21.4800\n",
      "Epoch [57/100], Training Loss: 7.3263, Validation Loss: 21.3930\n",
      "Epoch [58/100], Training Loss: 6.7080, Validation Loss: 21.3716\n",
      "Epoch [59/100], Training Loss: 9.0932, Validation Loss: 21.2891\n",
      "Epoch [60/100], Training Loss: 5.7549, Validation Loss: 21.3048\n",
      "Epoch [61/100], Training Loss: 6.6127, Validation Loss: 21.2565\n",
      "Epoch [62/100], Training Loss: 8.3169, Validation Loss: 21.2858\n",
      "Epoch [63/100], Training Loss: 7.2449, Validation Loss: 21.2381\n",
      "Epoch [64/100], Training Loss: 6.1873, Validation Loss: 21.1994\n",
      "Epoch [65/100], Training Loss: 8.5357, Validation Loss: 21.0910\n",
      "Epoch [66/100], Training Loss: 7.0758, Validation Loss: 21.0735\n",
      "Epoch [67/100], Training Loss: 5.8374, Validation Loss: 21.0860\n",
      "Epoch [68/100], Training Loss: 6.4613, Validation Loss: 21.0806\n",
      "Epoch [69/100], Training Loss: 6.1194, Validation Loss: 21.0555\n",
      "Epoch [70/100], Training Loss: 5.3974, Validation Loss: 21.0512\n",
      "Epoch [71/100], Training Loss: 5.2989, Validation Loss: 20.9335\n",
      "Epoch [72/100], Training Loss: 7.5521, Validation Loss: 21.0141\n",
      "Epoch [73/100], Training Loss: 5.0059, Validation Loss: 21.0408\n",
      "Epoch [74/100], Training Loss: 6.0598, Validation Loss: 20.9454\n",
      "Epoch [75/100], Training Loss: 7.1055, Validation Loss: 21.0118\n",
      "Epoch [76/100], Training Loss: 7.0395, Validation Loss: 21.0243\n",
      "Epoch [77/100], Training Loss: 7.0406, Validation Loss: 21.0247\n",
      "Epoch [78/100], Training Loss: 8.0746, Validation Loss: 20.8990\n",
      "Epoch [79/100], Training Loss: 7.0102, Validation Loss: 20.9366\n",
      "Epoch [80/100], Training Loss: 6.0055, Validation Loss: 20.9035\n",
      "Epoch [81/100], Training Loss: 5.7909, Validation Loss: 20.8646\n",
      "Epoch [82/100], Training Loss: 5.6746, Validation Loss: 20.8804\n",
      "Epoch [83/100], Training Loss: 8.0812, Validation Loss: 20.9105\n",
      "Epoch [84/100], Training Loss: 4.4647, Validation Loss: 20.8733\n",
      "Epoch [85/100], Training Loss: 8.5358, Validation Loss: 20.7590\n",
      "Epoch [86/100], Training Loss: 4.6645, Validation Loss: 20.8381\n",
      "Epoch [87/100], Training Loss: 7.5994, Validation Loss: 20.8941\n",
      "Epoch [88/100], Training Loss: 7.7030, Validation Loss: 20.7911\n",
      "Epoch [89/100], Training Loss: 6.2884, Validation Loss: 20.8071\n",
      "Epoch [90/100], Training Loss: 6.1428, Validation Loss: 20.7274\n",
      "Epoch [91/100], Training Loss: 6.0121, Validation Loss: 20.7813\n",
      "Epoch [92/100], Training Loss: 8.1572, Validation Loss: 20.8240\n",
      "Epoch [93/100], Training Loss: 6.0172, Validation Loss: 20.8965\n",
      "Epoch [94/100], Training Loss: 6.9309, Validation Loss: 20.8146\n",
      "Epoch [95/100], Training Loss: 8.0101, Validation Loss: 20.7418\n",
      "Epoch [96/100], Training Loss: 5.8663, Validation Loss: 20.6909\n",
      "Epoch [97/100], Training Loss: 6.6472, Validation Loss: 20.7373\n",
      "Epoch [98/100], Training Loss: 5.6452, Validation Loss: 20.7976\n",
      "Epoch [99/100], Training Loss: 7.7363, Validation Loss: 20.7468\n",
      "Epoch [100/100], Training Loss: 4.4924, Validation Loss: 20.7101\n",
      "F1-Score: 0.9908, Optimal Threshold: 17.4109\n",
      "Epoch [1/100], Training Loss: 131.4390, Validation Loss: 147.5507\n",
      "Epoch [2/100], Training Loss: 103.1149, Validation Loss: 117.7687\n",
      "Epoch [3/100], Training Loss: 84.1292, Validation Loss: 93.3847\n",
      "Epoch [4/100], Training Loss: 71.9909, Validation Loss: 72.8634\n",
      "Epoch [5/100], Training Loss: 41.3279, Validation Loss: 57.7180\n",
      "Epoch [6/100], Training Loss: 36.6055, Validation Loss: 47.7153\n",
      "Epoch [7/100], Training Loss: 38.9616, Validation Loss: 42.2344\n",
      "Epoch [8/100], Training Loss: 29.9297, Validation Loss: 40.0755\n",
      "Epoch [9/100], Training Loss: 30.6289, Validation Loss: 38.2203\n",
      "Epoch [10/100], Training Loss: 25.6253, Validation Loss: 36.8871\n",
      "Epoch [11/100], Training Loss: 29.8633, Validation Loss: 35.5394\n",
      "Epoch [12/100], Training Loss: 31.2877, Validation Loss: 34.3972\n",
      "Epoch [13/100], Training Loss: 25.7200, Validation Loss: 33.0564\n",
      "Epoch [14/100], Training Loss: 24.6147, Validation Loss: 31.9108\n",
      "Epoch [15/100], Training Loss: 23.9649, Validation Loss: 31.1047\n",
      "Epoch [16/100], Training Loss: 21.9752, Validation Loss: 29.8100\n",
      "Epoch [17/100], Training Loss: 20.5227, Validation Loss: 29.4011\n",
      "Epoch [18/100], Training Loss: 20.9793, Validation Loss: 28.5415\n",
      "Epoch [19/100], Training Loss: 24.1805, Validation Loss: 28.0840\n",
      "Epoch [20/100], Training Loss: 23.1855, Validation Loss: 27.5998\n",
      "Epoch [21/100], Training Loss: 18.4637, Validation Loss: 27.4482\n",
      "Epoch [22/100], Training Loss: 20.9076, Validation Loss: 26.8277\n",
      "Epoch [23/100], Training Loss: 18.4952, Validation Loss: 26.4837\n",
      "Epoch [24/100], Training Loss: 17.4913, Validation Loss: 26.3701\n",
      "Epoch [25/100], Training Loss: 18.2597, Validation Loss: 26.3769\n",
      "Epoch [26/100], Training Loss: 20.7647, Validation Loss: 25.8183\n",
      "Epoch [27/100], Training Loss: 20.9085, Validation Loss: 25.7451\n",
      "Epoch [28/100], Training Loss: 18.3724, Validation Loss: 25.6477\n",
      "Epoch [29/100], Training Loss: 15.1840, Validation Loss: 25.4593\n",
      "Epoch [30/100], Training Loss: 21.9991, Validation Loss: 25.3917\n",
      "Epoch [31/100], Training Loss: 23.3129, Validation Loss: 25.1724\n",
      "Epoch [32/100], Training Loss: 17.4123, Validation Loss: 25.1851\n",
      "Epoch [33/100], Training Loss: 19.0921, Validation Loss: 24.9799\n",
      "Epoch [34/100], Training Loss: 19.7583, Validation Loss: 24.9467\n",
      "Epoch [35/100], Training Loss: 17.8238, Validation Loss: 24.7608\n",
      "Epoch [36/100], Training Loss: 14.8289, Validation Loss: 24.7446\n",
      "Epoch [37/100], Training Loss: 19.5117, Validation Loss: 24.5550\n",
      "Epoch [38/100], Training Loss: 17.0183, Validation Loss: 24.5579\n",
      "Epoch [39/100], Training Loss: 17.3963, Validation Loss: 24.2190\n",
      "Epoch [40/100], Training Loss: 20.8383, Validation Loss: 24.0767\n",
      "Epoch [41/100], Training Loss: 15.7769, Validation Loss: 24.1776\n",
      "Epoch [42/100], Training Loss: 16.4354, Validation Loss: 24.0302\n",
      "Epoch [43/100], Training Loss: 14.8740, Validation Loss: 23.8429\n",
      "Epoch [44/100], Training Loss: 21.7926, Validation Loss: 23.7850\n",
      "Epoch [45/100], Training Loss: 19.0028, Validation Loss: 23.7441\n",
      "Epoch [46/100], Training Loss: 16.1984, Validation Loss: 23.4770\n",
      "Epoch [47/100], Training Loss: 15.6196, Validation Loss: 23.5409\n",
      "Epoch [48/100], Training Loss: 16.2412, Validation Loss: 23.3297\n",
      "Epoch [49/100], Training Loss: 18.5502, Validation Loss: 23.1962\n",
      "Epoch [50/100], Training Loss: 18.8438, Validation Loss: 23.4121\n",
      "Epoch [51/100], Training Loss: 18.0546, Validation Loss: 23.1984\n",
      "Epoch [52/100], Training Loss: 16.5627, Validation Loss: 23.0851\n",
      "Epoch [53/100], Training Loss: 17.9819, Validation Loss: 23.1017\n",
      "Epoch [54/100], Training Loss: 19.4081, Validation Loss: 22.9082\n",
      "Epoch [55/100], Training Loss: 15.9446, Validation Loss: 22.8716\n",
      "Epoch [56/100], Training Loss: 14.5282, Validation Loss: 22.8570\n",
      "Epoch [57/100], Training Loss: 19.1629, Validation Loss: 22.7047\n",
      "Epoch [58/100], Training Loss: 20.6604, Validation Loss: 22.6734\n",
      "Epoch [59/100], Training Loss: 13.3187, Validation Loss: 22.5826\n",
      "Epoch [60/100], Training Loss: 14.6751, Validation Loss: 22.5495\n",
      "Epoch [61/100], Training Loss: 13.6760, Validation Loss: 22.5134\n",
      "Epoch [62/100], Training Loss: 11.7856, Validation Loss: 22.4419\n",
      "Epoch [63/100], Training Loss: 15.0314, Validation Loss: 22.3236\n",
      "Epoch [64/100], Training Loss: 14.5350, Validation Loss: 22.3067\n",
      "Epoch [65/100], Training Loss: 15.1121, Validation Loss: 22.2954\n",
      "Epoch [66/100], Training Loss: 16.5492, Validation Loss: 22.3321\n",
      "Epoch [67/100], Training Loss: 12.1033, Validation Loss: 22.2462\n",
      "Epoch [68/100], Training Loss: 14.8178, Validation Loss: 22.0818\n",
      "Epoch [69/100], Training Loss: 17.4386, Validation Loss: 22.1337\n",
      "Epoch [70/100], Training Loss: 16.8031, Validation Loss: 21.9984\n",
      "Epoch [71/100], Training Loss: 15.9782, Validation Loss: 21.9263\n",
      "Epoch [72/100], Training Loss: 15.8099, Validation Loss: 21.9201\n",
      "Epoch [73/100], Training Loss: 18.0331, Validation Loss: 21.9643\n",
      "Epoch [74/100], Training Loss: 13.3137, Validation Loss: 21.8117\n",
      "Epoch [75/100], Training Loss: 14.2507, Validation Loss: 21.8599\n",
      "Epoch [76/100], Training Loss: 15.3745, Validation Loss: 21.8148\n",
      "Epoch [77/100], Training Loss: 19.6917, Validation Loss: 21.7304\n",
      "Epoch [78/100], Training Loss: 14.6325, Validation Loss: 21.8011\n",
      "Epoch [79/100], Training Loss: 15.1240, Validation Loss: 21.6519\n",
      "Epoch [80/100], Training Loss: 15.0284, Validation Loss: 21.6972\n",
      "Epoch [81/100], Training Loss: 15.4116, Validation Loss: 21.6585\n",
      "Epoch [82/100], Training Loss: 16.0082, Validation Loss: 21.6240\n",
      "Epoch [83/100], Training Loss: 16.5468, Validation Loss: 21.4603\n",
      "Epoch [84/100], Training Loss: 13.9912, Validation Loss: 21.5454\n",
      "Epoch [85/100], Training Loss: 12.2793, Validation Loss: 21.4354\n",
      "Epoch [86/100], Training Loss: 13.3297, Validation Loss: 21.4356\n",
      "Epoch [87/100], Training Loss: 13.1067, Validation Loss: 21.4403\n",
      "Epoch [88/100], Training Loss: 15.9651, Validation Loss: 21.3622\n",
      "Epoch [89/100], Training Loss: 16.1574, Validation Loss: 21.3838\n",
      "Epoch [90/100], Training Loss: 14.0060, Validation Loss: 21.3814\n",
      "Epoch [91/100], Training Loss: 17.9681, Validation Loss: 21.3166\n",
      "Epoch [92/100], Training Loss: 14.5772, Validation Loss: 21.3152\n",
      "Epoch [93/100], Training Loss: 17.2464, Validation Loss: 21.2996\n",
      "Epoch [94/100], Training Loss: 12.4624, Validation Loss: 21.3469\n",
      "Epoch [95/100], Training Loss: 14.2018, Validation Loss: 21.2603\n",
      "Epoch [96/100], Training Loss: 13.3668, Validation Loss: 21.2207\n",
      "Epoch [97/100], Training Loss: 16.1983, Validation Loss: 21.1726\n",
      "Epoch [98/100], Training Loss: 12.2278, Validation Loss: 21.1689\n",
      "Epoch [99/100], Training Loss: 14.2098, Validation Loss: 21.1958\n",
      "Epoch [100/100], Training Loss: 16.7203, Validation Loss: 21.2254\n",
      "F1-Score: 0.9167, Optimal Threshold: 17.2629\n",
      "Epoch [1/100], Training Loss: 18.0666, Validation Loss: 77.8925\n",
      "Epoch [2/100], Training Loss: 9.3810, Validation Loss: 40.1568\n",
      "Epoch [3/100], Training Loss: 5.9930, Validation Loss: 25.6079\n",
      "Epoch [4/100], Training Loss: 5.1204, Validation Loss: 22.7114\n",
      "Epoch [5/100], Training Loss: 5.4685, Validation Loss: 21.6983\n",
      "Epoch [6/100], Training Loss: 5.8956, Validation Loss: 21.0871\n",
      "Epoch [7/100], Training Loss: 3.5891, Validation Loss: 20.2163\n",
      "Epoch [8/100], Training Loss: 4.0937, Validation Loss: 19.3357\n",
      "Epoch [9/100], Training Loss: 4.3939, Validation Loss: 18.4554\n",
      "Epoch [10/100], Training Loss: 2.8270, Validation Loss: 17.7931\n",
      "Epoch [11/100], Training Loss: 4.1907, Validation Loss: 17.2602\n",
      "Epoch [12/100], Training Loss: 2.0094, Validation Loss: 16.9523\n",
      "Epoch [13/100], Training Loss: 3.0119, Validation Loss: 16.5765\n",
      "Epoch [14/100], Training Loss: 2.9700, Validation Loss: 16.3257\n",
      "Epoch [15/100], Training Loss: 2.2602, Validation Loss: 16.1878\n",
      "Epoch [16/100], Training Loss: 3.1552, Validation Loss: 15.8996\n",
      "Epoch [17/100], Training Loss: 3.0927, Validation Loss: 15.5551\n",
      "Epoch [18/100], Training Loss: 1.9901, Validation Loss: 15.4269\n",
      "Epoch [19/100], Training Loss: 3.2177, Validation Loss: 15.2443\n",
      "Epoch [20/100], Training Loss: 3.7024, Validation Loss: 15.0596\n",
      "Epoch [21/100], Training Loss: 2.6669, Validation Loss: 14.8681\n",
      "Epoch [22/100], Training Loss: 5.3514, Validation Loss: 14.7507\n",
      "Epoch [23/100], Training Loss: 3.6961, Validation Loss: 14.5546\n",
      "Epoch [24/100], Training Loss: 3.4606, Validation Loss: 14.4868\n",
      "Epoch [25/100], Training Loss: 4.0296, Validation Loss: 14.3015\n",
      "Epoch [26/100], Training Loss: 3.3059, Validation Loss: 14.2205\n",
      "Epoch [27/100], Training Loss: 2.2829, Validation Loss: 14.0766\n",
      "Epoch [28/100], Training Loss: 2.8395, Validation Loss: 14.0235\n",
      "Epoch [29/100], Training Loss: 2.0138, Validation Loss: 13.8902\n",
      "Epoch [30/100], Training Loss: 5.1297, Validation Loss: 13.7920\n",
      "Epoch [31/100], Training Loss: 1.3123, Validation Loss: 13.6409\n",
      "Epoch [32/100], Training Loss: 2.7347, Validation Loss: 13.6909\n",
      "Epoch [33/100], Training Loss: 1.7860, Validation Loss: 13.5631\n",
      "Epoch [34/100], Training Loss: 2.0841, Validation Loss: 13.4661\n",
      "Epoch [35/100], Training Loss: 1.9491, Validation Loss: 13.4551\n",
      "Epoch [36/100], Training Loss: 2.4684, Validation Loss: 13.4034\n",
      "Epoch [37/100], Training Loss: 2.9025, Validation Loss: 13.3541\n",
      "Epoch [38/100], Training Loss: 2.2728, Validation Loss: 13.3040\n",
      "Epoch [39/100], Training Loss: 2.1902, Validation Loss: 13.2417\n",
      "Epoch [40/100], Training Loss: 3.0192, Validation Loss: 13.1728\n",
      "Epoch [41/100], Training Loss: 1.7601, Validation Loss: 13.1729\n",
      "Epoch [42/100], Training Loss: 2.5978, Validation Loss: 13.1457\n",
      "Epoch [43/100], Training Loss: 2.0077, Validation Loss: 13.0368\n",
      "Epoch [44/100], Training Loss: 1.3743, Validation Loss: 13.0250\n",
      "Epoch [45/100], Training Loss: 1.7872, Validation Loss: 13.0195\n",
      "Epoch [46/100], Training Loss: 2.1676, Validation Loss: 12.9939\n",
      "Epoch [47/100], Training Loss: 2.4770, Validation Loss: 12.9681\n",
      "Epoch [48/100], Training Loss: 3.9409, Validation Loss: 12.9577\n",
      "Epoch [49/100], Training Loss: 2.3201, Validation Loss: 12.9391\n",
      "Epoch [50/100], Training Loss: 2.3453, Validation Loss: 12.9070\n",
      "Epoch [51/100], Training Loss: 2.7708, Validation Loss: 12.8450\n",
      "Epoch [52/100], Training Loss: 2.5472, Validation Loss: 12.8772\n",
      "Epoch [53/100], Training Loss: 3.4489, Validation Loss: 12.8520\n",
      "Epoch [54/100], Training Loss: 2.7530, Validation Loss: 12.8046\n",
      "Epoch [55/100], Training Loss: 2.0041, Validation Loss: 12.8184\n",
      "Epoch [56/100], Training Loss: 3.8597, Validation Loss: 12.7969\n",
      "Epoch [57/100], Training Loss: 2.2575, Validation Loss: 12.7481\n",
      "Epoch [58/100], Training Loss: 2.2345, Validation Loss: 12.7931\n",
      "Epoch [59/100], Training Loss: 2.0451, Validation Loss: 12.7739\n",
      "Epoch [60/100], Training Loss: 3.3475, Validation Loss: 12.7534\n",
      "Epoch [61/100], Training Loss: 2.6931, Validation Loss: 12.7454\n",
      "Epoch [62/100], Training Loss: 2.1368, Validation Loss: 12.7241\n",
      "Epoch [63/100], Training Loss: 2.8693, Validation Loss: 12.6918\n",
      "Epoch [64/100], Training Loss: 1.8261, Validation Loss: 12.7134\n",
      "Epoch [65/100], Training Loss: 3.8925, Validation Loss: 12.6537\n",
      "Epoch [66/100], Training Loss: 2.4683, Validation Loss: 12.6786\n",
      "Epoch [67/100], Training Loss: 2.5930, Validation Loss: 12.6981\n",
      "Epoch [68/100], Training Loss: 2.5358, Validation Loss: 12.6532\n",
      "Epoch [69/100], Training Loss: 1.9075, Validation Loss: 12.6737\n",
      "Epoch [70/100], Training Loss: 1.9846, Validation Loss: 12.6429\n",
      "Epoch [71/100], Training Loss: 2.1903, Validation Loss: 12.6373\n",
      "Epoch [72/100], Training Loss: 2.4428, Validation Loss: 12.6281\n",
      "Epoch [73/100], Training Loss: 2.3829, Validation Loss: 12.6124\n",
      "Epoch [74/100], Training Loss: 4.9345, Validation Loss: 12.6370\n",
      "Epoch [75/100], Training Loss: 2.0304, Validation Loss: 12.6023\n",
      "Epoch [76/100], Training Loss: 1.7122, Validation Loss: 12.5697\n",
      "Epoch [77/100], Training Loss: 3.4575, Validation Loss: 12.6035\n",
      "Epoch [78/100], Training Loss: 2.4672, Validation Loss: 12.6004\n",
      "Epoch [79/100], Training Loss: 2.5559, Validation Loss: 12.6239\n",
      "Epoch [80/100], Training Loss: 2.8440, Validation Loss: 12.6054\n",
      "Epoch [81/100], Training Loss: 2.3438, Validation Loss: 12.6091\n",
      "Epoch [82/100], Training Loss: 3.1715, Validation Loss: 12.5834\n",
      "Epoch [83/100], Training Loss: 2.0022, Validation Loss: 12.5458\n",
      "Epoch [84/100], Training Loss: 2.7381, Validation Loss: 12.5732\n",
      "Epoch [85/100], Training Loss: 3.0393, Validation Loss: 12.5739\n",
      "Epoch [86/100], Training Loss: 2.9102, Validation Loss: 12.5757\n",
      "Epoch [87/100], Training Loss: 1.6472, Validation Loss: 12.5036\n",
      "Epoch [88/100], Training Loss: 2.2059, Validation Loss: 12.5449\n",
      "Epoch [89/100], Training Loss: 1.4904, Validation Loss: 12.4983\n",
      "Epoch [90/100], Training Loss: 1.7133, Validation Loss: 12.5121\n",
      "Epoch [91/100], Training Loss: 1.9178, Validation Loss: 12.5351\n",
      "Epoch [92/100], Training Loss: 2.7986, Validation Loss: 12.5394\n",
      "Epoch [93/100], Training Loss: 2.0184, Validation Loss: 12.5273\n",
      "Epoch [94/100], Training Loss: 2.1305, Validation Loss: 12.5172\n",
      "Epoch [95/100], Training Loss: 2.6038, Validation Loss: 12.5313\n",
      "Epoch [96/100], Training Loss: 2.2453, Validation Loss: 12.5178\n",
      "Epoch [97/100], Training Loss: 2.7267, Validation Loss: 12.5295\n",
      "Epoch [98/100], Training Loss: 2.3165, Validation Loss: 12.5083\n",
      "Epoch [99/100], Training Loss: 1.9583, Validation Loss: 12.5092\n",
      "Epoch [100/100], Training Loss: 1.8813, Validation Loss: 12.5432\n",
      "F1-Score: 0.8977, Optimal Threshold: 9.8517\n",
      "Epoch [1/100], Training Loss: 32.0795, Validation Loss: 111.8317\n",
      "Epoch [2/100], Training Loss: 28.0968, Validation Loss: 79.5026\n",
      "Epoch [3/100], Training Loss: 19.5674, Validation Loss: 55.6250\n",
      "Epoch [4/100], Training Loss: 10.9280, Validation Loss: 40.6509\n",
      "Epoch [5/100], Training Loss: 6.6732, Validation Loss: 33.1045\n",
      "Epoch [6/100], Training Loss: 11.6704, Validation Loss: 30.2246\n",
      "Epoch [7/100], Training Loss: 5.7132, Validation Loss: 28.8762\n",
      "Epoch [8/100], Training Loss: 12.9553, Validation Loss: 27.3567\n",
      "Epoch [9/100], Training Loss: 6.3931, Validation Loss: 25.9619\n",
      "Epoch [10/100], Training Loss: 6.7546, Validation Loss: 24.6288\n",
      "Epoch [11/100], Training Loss: 5.3524, Validation Loss: 23.4463\n",
      "Epoch [12/100], Training Loss: 4.2448, Validation Loss: 22.4071\n",
      "Epoch [13/100], Training Loss: 5.4636, Validation Loss: 21.5578\n",
      "Epoch [14/100], Training Loss: 4.6865, Validation Loss: 21.2349\n",
      "Epoch [15/100], Training Loss: 5.1226, Validation Loss: 20.7975\n",
      "Epoch [16/100], Training Loss: 4.0074, Validation Loss: 20.3794\n",
      "Epoch [17/100], Training Loss: 5.4474, Validation Loss: 20.1933\n",
      "Epoch [18/100], Training Loss: 4.6014, Validation Loss: 19.9429\n",
      "Epoch [19/100], Training Loss: 4.6013, Validation Loss: 19.7755\n",
      "Epoch [20/100], Training Loss: 4.2995, Validation Loss: 19.5644\n",
      "Epoch [21/100], Training Loss: 4.4140, Validation Loss: 19.2581\n",
      "Epoch [22/100], Training Loss: 5.0933, Validation Loss: 19.1778\n",
      "Epoch [23/100], Training Loss: 4.1343, Validation Loss: 18.9501\n",
      "Epoch [24/100], Training Loss: 4.1630, Validation Loss: 18.5717\n",
      "Epoch [25/100], Training Loss: 9.1843, Validation Loss: 18.5375\n",
      "Epoch [26/100], Training Loss: 3.4256, Validation Loss: 18.5474\n",
      "Epoch [27/100], Training Loss: 4.4427, Validation Loss: 18.2355\n",
      "Epoch [28/100], Training Loss: 3.9701, Validation Loss: 18.1516\n",
      "Epoch [29/100], Training Loss: 3.1198, Validation Loss: 17.9727\n",
      "Epoch [30/100], Training Loss: 3.9245, Validation Loss: 17.6917\n",
      "Epoch [31/100], Training Loss: 3.6129, Validation Loss: 17.4871\n",
      "Epoch [32/100], Training Loss: 2.7023, Validation Loss: 17.6077\n",
      "Epoch [33/100], Training Loss: 4.5288, Validation Loss: 17.3783\n",
      "Epoch [34/100], Training Loss: 3.1481, Validation Loss: 17.2403\n",
      "Epoch [35/100], Training Loss: 3.1823, Validation Loss: 17.1185\n",
      "Epoch [36/100], Training Loss: 3.3936, Validation Loss: 17.1576\n",
      "Epoch [37/100], Training Loss: 3.4227, Validation Loss: 16.8979\n",
      "Epoch [38/100], Training Loss: 3.0578, Validation Loss: 16.9336\n",
      "Epoch [39/100], Training Loss: 6.2192, Validation Loss: 16.6985\n",
      "Epoch [40/100], Training Loss: 2.9324, Validation Loss: 16.5887\n",
      "Epoch [41/100], Training Loss: 6.8026, Validation Loss: 16.6302\n",
      "Epoch [42/100], Training Loss: 3.0679, Validation Loss: 16.3544\n",
      "Epoch [43/100], Training Loss: 1.6449, Validation Loss: 16.4166\n",
      "Epoch [44/100], Training Loss: 3.6045, Validation Loss: 16.4407\n",
      "Epoch [45/100], Training Loss: 2.8650, Validation Loss: 16.1951\n",
      "Epoch [46/100], Training Loss: 6.8642, Validation Loss: 16.1732\n",
      "Epoch [47/100], Training Loss: 3.7656, Validation Loss: 16.1603\n",
      "Epoch [48/100], Training Loss: 2.6952, Validation Loss: 16.0439\n",
      "Epoch [49/100], Training Loss: 4.9005, Validation Loss: 15.9329\n",
      "Epoch [50/100], Training Loss: 4.4490, Validation Loss: 15.8936\n",
      "Epoch [51/100], Training Loss: 3.0983, Validation Loss: 15.8532\n",
      "Epoch [52/100], Training Loss: 2.7607, Validation Loss: 15.8096\n",
      "Epoch [53/100], Training Loss: 2.2982, Validation Loss: 15.7984\n",
      "Epoch [54/100], Training Loss: 2.8486, Validation Loss: 15.7326\n",
      "Epoch [55/100], Training Loss: 2.3023, Validation Loss: 15.6239\n",
      "Epoch [56/100], Training Loss: 2.8030, Validation Loss: 15.5746\n",
      "Epoch [57/100], Training Loss: 4.0995, Validation Loss: 15.5030\n",
      "Epoch [58/100], Training Loss: 2.7346, Validation Loss: 15.5688\n",
      "Epoch [59/100], Training Loss: 3.2790, Validation Loss: 15.5851\n",
      "Epoch [60/100], Training Loss: 2.5258, Validation Loss: 15.4289\n",
      "Epoch [61/100], Training Loss: 2.8114, Validation Loss: 15.4455\n",
      "Epoch [62/100], Training Loss: 3.1637, Validation Loss: 15.4064\n",
      "Epoch [63/100], Training Loss: 3.4998, Validation Loss: 15.3107\n",
      "Epoch [64/100], Training Loss: 3.4101, Validation Loss: 15.3565\n",
      "Epoch [65/100], Training Loss: 2.5154, Validation Loss: 15.2584\n",
      "Epoch [66/100], Training Loss: 3.5086, Validation Loss: 15.3232\n",
      "Epoch [67/100], Training Loss: 7.4159, Validation Loss: 15.2185\n",
      "Epoch [68/100], Training Loss: 5.1824, Validation Loss: 15.2646\n",
      "Epoch [69/100], Training Loss: 1.9738, Validation Loss: 15.2747\n",
      "Epoch [70/100], Training Loss: 7.4878, Validation Loss: 15.1085\n",
      "Epoch [71/100], Training Loss: 1.8806, Validation Loss: 15.2537\n",
      "Epoch [72/100], Training Loss: 2.8534, Validation Loss: 15.1512\n",
      "Epoch [73/100], Training Loss: 5.8593, Validation Loss: 15.0916\n",
      "Epoch [74/100], Training Loss: 1.6117, Validation Loss: 15.0912\n",
      "Epoch [75/100], Training Loss: 2.2866, Validation Loss: 15.1008\n",
      "Epoch [76/100], Training Loss: 3.1581, Validation Loss: 15.0712\n",
      "Epoch [77/100], Training Loss: 3.1057, Validation Loss: 15.0585\n",
      "Epoch [78/100], Training Loss: 3.6268, Validation Loss: 15.0623\n",
      "Epoch [79/100], Training Loss: 4.8397, Validation Loss: 15.0611\n",
      "Epoch [80/100], Training Loss: 2.0624, Validation Loss: 15.0083\n",
      "Epoch [81/100], Training Loss: 2.4736, Validation Loss: 15.0127\n",
      "Epoch [82/100], Training Loss: 2.3619, Validation Loss: 15.0345\n",
      "Epoch [83/100], Training Loss: 2.6939, Validation Loss: 15.0000\n",
      "Epoch [84/100], Training Loss: 3.8141, Validation Loss: 14.9658\n",
      "Epoch [85/100], Training Loss: 2.4770, Validation Loss: 14.9887\n",
      "Epoch [86/100], Training Loss: 3.2150, Validation Loss: 14.9526\n",
      "Epoch [87/100], Training Loss: 6.5438, Validation Loss: 14.9878\n",
      "Epoch [88/100], Training Loss: 4.2055, Validation Loss: 14.9869\n",
      "Epoch [89/100], Training Loss: 2.8272, Validation Loss: 14.9002\n",
      "Epoch [90/100], Training Loss: 5.9884, Validation Loss: 14.9632\n",
      "Epoch [91/100], Training Loss: 2.2327, Validation Loss: 14.9449\n",
      "Epoch [92/100], Training Loss: 4.4684, Validation Loss: 14.9254\n",
      "Epoch [93/100], Training Loss: 1.6064, Validation Loss: 14.9095\n",
      "Epoch [94/100], Training Loss: 3.3546, Validation Loss: 14.9398\n",
      "Epoch [95/100], Training Loss: 1.4413, Validation Loss: 14.9077\n",
      "Epoch [96/100], Training Loss: 2.1320, Validation Loss: 14.9045\n",
      "Epoch [97/100], Training Loss: 5.3931, Validation Loss: 14.8847\n",
      "Epoch [98/100], Training Loss: 2.7249, Validation Loss: 14.8433\n",
      "Epoch [99/100], Training Loss: 2.6104, Validation Loss: 14.8858\n",
      "Epoch [100/100], Training Loss: 2.2006, Validation Loss: 14.8803\n",
      "F1-Score: 0.9060, Optimal Threshold: 11.9465\n",
      "Epoch [1/100], Training Loss: 5.5807, Validation Loss: 82.2506\n",
      "Epoch [2/100], Training Loss: 3.0752, Validation Loss: 43.9187\n",
      "Epoch [3/100], Training Loss: 0.8181, Validation Loss: 28.5929\n",
      "Epoch [4/100], Training Loss: 1.3566, Validation Loss: 25.0379\n",
      "Epoch [5/100], Training Loss: 1.0109, Validation Loss: 23.7827\n",
      "Epoch [6/100], Training Loss: 2.5400, Validation Loss: 22.4743\n",
      "Epoch [7/100], Training Loss: 1.7695, Validation Loss: 21.2196\n",
      "Epoch [8/100], Training Loss: 0.4825, Validation Loss: 20.0420\n",
      "Epoch [9/100], Training Loss: 0.7309, Validation Loss: 19.1697\n",
      "Epoch [10/100], Training Loss: 1.5737, Validation Loss: 18.5205\n",
      "Epoch [11/100], Training Loss: 0.5917, Validation Loss: 18.0118\n",
      "Epoch [12/100], Training Loss: 0.7924, Validation Loss: 17.7093\n",
      "Epoch [13/100], Training Loss: 0.5730, Validation Loss: 17.4317\n",
      "Epoch [14/100], Training Loss: 0.6298, Validation Loss: 17.1378\n",
      "Epoch [15/100], Training Loss: 0.8962, Validation Loss: 16.8583\n",
      "Epoch [16/100], Training Loss: 0.4154, Validation Loss: 16.6874\n",
      "Epoch [17/100], Training Loss: 0.5480, Validation Loss: 16.4490\n",
      "Epoch [18/100], Training Loss: 1.1334, Validation Loss: 16.2369\n",
      "Epoch [19/100], Training Loss: 0.7912, Validation Loss: 16.0417\n",
      "Epoch [20/100], Training Loss: 3.2443, Validation Loss: 15.8804\n",
      "Epoch [21/100], Training Loss: 0.5362, Validation Loss: 15.6668\n",
      "Epoch [22/100], Training Loss: 0.3060, Validation Loss: 15.5487\n",
      "Epoch [23/100], Training Loss: 0.3878, Validation Loss: 15.3678\n",
      "Epoch [24/100], Training Loss: 0.6999, Validation Loss: 15.2582\n",
      "Epoch [25/100], Training Loss: 0.3768, Validation Loss: 15.0950\n",
      "Epoch [26/100], Training Loss: 0.2562, Validation Loss: 14.9692\n",
      "Epoch [27/100], Training Loss: 0.2961, Validation Loss: 14.9115\n",
      "Epoch [28/100], Training Loss: 0.6737, Validation Loss: 14.7505\n",
      "Epoch [29/100], Training Loss: 0.2315, Validation Loss: 14.7160\n",
      "Epoch [30/100], Training Loss: 0.5421, Validation Loss: 14.5858\n",
      "Epoch [31/100], Training Loss: 0.3431, Validation Loss: 14.4871\n",
      "Epoch [32/100], Training Loss: 1.1957, Validation Loss: 14.4371\n",
      "Epoch [33/100], Training Loss: 0.2868, Validation Loss: 14.3820\n",
      "Epoch [34/100], Training Loss: 1.6859, Validation Loss: 14.2967\n",
      "Epoch [35/100], Training Loss: 1.0355, Validation Loss: 14.2202\n",
      "Epoch [36/100], Training Loss: 0.2226, Validation Loss: 14.1595\n",
      "Epoch [37/100], Training Loss: 0.2803, Validation Loss: 14.1362\n",
      "Epoch [38/100], Training Loss: 0.5457, Validation Loss: 14.0872\n",
      "Epoch [39/100], Training Loss: 0.9113, Validation Loss: 14.0564\n",
      "Epoch [40/100], Training Loss: 0.5598, Validation Loss: 14.0158\n",
      "Epoch [41/100], Training Loss: 1.1575, Validation Loss: 13.9731\n",
      "Epoch [42/100], Training Loss: 0.2946, Validation Loss: 13.9588\n",
      "Epoch [43/100], Training Loss: 0.8183, Validation Loss: 13.8911\n",
      "Epoch [44/100], Training Loss: 0.5654, Validation Loss: 13.9160\n",
      "Epoch [45/100], Training Loss: 0.5568, Validation Loss: 13.8214\n",
      "Epoch [46/100], Training Loss: 0.8516, Validation Loss: 13.8185\n",
      "Epoch [47/100], Training Loss: 0.3649, Validation Loss: 13.8399\n",
      "Epoch [48/100], Training Loss: 0.5760, Validation Loss: 13.7845\n",
      "Epoch [49/100], Training Loss: 0.3940, Validation Loss: 13.7496\n",
      "Epoch [50/100], Training Loss: 0.8344, Validation Loss: 13.7546\n",
      "Epoch [51/100], Training Loss: 0.7903, Validation Loss: 13.7348\n",
      "Epoch [52/100], Training Loss: 0.5254, Validation Loss: 13.6989\n",
      "Epoch [53/100], Training Loss: 0.4584, Validation Loss: 13.6805\n",
      "Epoch [54/100], Training Loss: 0.8381, Validation Loss: 13.6895\n",
      "Epoch [55/100], Training Loss: 0.3660, Validation Loss: 13.6867\n",
      "Epoch [56/100], Training Loss: 0.8198, Validation Loss: 13.6766\n",
      "Epoch [57/100], Training Loss: 0.4781, Validation Loss: 13.6460\n",
      "Epoch [58/100], Training Loss: 0.5654, Validation Loss: 13.6611\n",
      "Epoch [59/100], Training Loss: 0.6807, Validation Loss: 13.6347\n",
      "Epoch [60/100], Training Loss: 0.4188, Validation Loss: 13.6092\n",
      "Epoch [61/100], Training Loss: 0.5980, Validation Loss: 13.5951\n",
      "Epoch [62/100], Training Loss: 0.7948, Validation Loss: 13.5935\n",
      "Epoch [63/100], Training Loss: 0.5895, Validation Loss: 13.6152\n",
      "Epoch [64/100], Training Loss: 0.3552, Validation Loss: 13.5807\n",
      "Epoch [65/100], Training Loss: 0.5155, Validation Loss: 13.5687\n",
      "Epoch [66/100], Training Loss: 0.3350, Validation Loss: 13.6174\n",
      "Epoch [67/100], Training Loss: 0.5400, Validation Loss: 13.5778\n",
      "Epoch [68/100], Training Loss: 0.5177, Validation Loss: 13.5529\n",
      "Epoch [69/100], Training Loss: 0.1821, Validation Loss: 13.5832\n",
      "Epoch [70/100], Training Loss: 1.1805, Validation Loss: 13.5437\n",
      "Epoch [71/100], Training Loss: 0.4343, Validation Loss: 13.5481\n",
      "Epoch [72/100], Training Loss: 0.4640, Validation Loss: 13.5431\n",
      "Epoch [73/100], Training Loss: 0.8864, Validation Loss: 13.5149\n",
      "Epoch [74/100], Training Loss: 0.5100, Validation Loss: 13.5181\n",
      "Epoch [75/100], Training Loss: 0.6156, Validation Loss: 13.5284\n",
      "Epoch [76/100], Training Loss: 0.3881, Validation Loss: 13.5049\n",
      "Epoch [77/100], Training Loss: 1.5082, Validation Loss: 13.5148\n",
      "Epoch [78/100], Training Loss: 0.3901, Validation Loss: 13.4916\n",
      "Epoch [79/100], Training Loss: 0.4087, Validation Loss: 13.5420\n",
      "Epoch [80/100], Training Loss: 0.3331, Validation Loss: 13.5435\n",
      "Epoch [81/100], Training Loss: 0.4251, Validation Loss: 13.5026\n",
      "Epoch [82/100], Training Loss: 0.7346, Validation Loss: 13.4767\n",
      "Epoch [83/100], Training Loss: 0.2185, Validation Loss: 13.4859\n",
      "Epoch [84/100], Training Loss: 0.2332, Validation Loss: 13.4870\n",
      "Epoch [85/100], Training Loss: 0.9269, Validation Loss: 13.4779\n",
      "Epoch [86/100], Training Loss: 0.6217, Validation Loss: 13.4657\n",
      "Epoch [87/100], Training Loss: 0.4005, Validation Loss: 13.4624\n",
      "Epoch [88/100], Training Loss: 0.3288, Validation Loss: 13.4523\n",
      "Epoch [89/100], Training Loss: 0.4811, Validation Loss: 13.4522\n",
      "Epoch [90/100], Training Loss: 0.8027, Validation Loss: 13.4365\n",
      "Epoch [91/100], Training Loss: 0.2539, Validation Loss: 13.4182\n",
      "Epoch [92/100], Training Loss: 0.2313, Validation Loss: 13.4119\n",
      "Epoch [93/100], Training Loss: 0.2792, Validation Loss: 13.4539\n",
      "Epoch [94/100], Training Loss: 0.2092, Validation Loss: 13.3940\n",
      "Epoch [95/100], Training Loss: 0.2313, Validation Loss: 13.3984\n",
      "Epoch [96/100], Training Loss: 0.6548, Validation Loss: 13.4294\n",
      "Epoch [97/100], Training Loss: 0.4922, Validation Loss: 13.4249\n",
      "Epoch [98/100], Training Loss: 0.3736, Validation Loss: 13.4375\n",
      "Epoch [99/100], Training Loss: 0.3032, Validation Loss: 13.4401\n",
      "Epoch [100/100], Training Loss: 0.9648, Validation Loss: 13.4262\n",
      "F1-Score: 0.8852, Optimal Threshold: 10.6821\n",
      "Epoch [1/100], Training Loss: 79.9461, Validation Loss: 125.6921\n",
      "Epoch [2/100], Training Loss: 54.6010, Validation Loss: 95.2114\n",
      "Epoch [3/100], Training Loss: 51.4658, Validation Loss: 71.9367\n",
      "Epoch [4/100], Training Loss: 31.1566, Validation Loss: 54.0701\n",
      "Epoch [5/100], Training Loss: 23.5553, Validation Loss: 41.5298\n",
      "Epoch [6/100], Training Loss: 17.4741, Validation Loss: 35.1200\n",
      "Epoch [7/100], Training Loss: 17.3235, Validation Loss: 32.7692\n",
      "Epoch [8/100], Training Loss: 15.0757, Validation Loss: 31.3914\n",
      "Epoch [9/100], Training Loss: 18.9489, Validation Loss: 30.4170\n",
      "Epoch [10/100], Training Loss: 13.6069, Validation Loss: 29.4007\n",
      "Epoch [11/100], Training Loss: 12.7586, Validation Loss: 28.0564\n",
      "Epoch [12/100], Training Loss: 12.8284, Validation Loss: 26.7949\n",
      "Epoch [13/100], Training Loss: 16.0126, Validation Loss: 25.3490\n",
      "Epoch [14/100], Training Loss: 14.2034, Validation Loss: 24.4982\n",
      "Epoch [15/100], Training Loss: 11.9024, Validation Loss: 23.7039\n",
      "Epoch [16/100], Training Loss: 11.0007, Validation Loss: 22.7176\n",
      "Epoch [17/100], Training Loss: 10.0439, Validation Loss: 22.4051\n",
      "Epoch [18/100], Training Loss: 11.0566, Validation Loss: 21.8943\n",
      "Epoch [19/100], Training Loss: 11.4113, Validation Loss: 21.4807\n",
      "Epoch [20/100], Training Loss: 9.5857, Validation Loss: 21.5209\n",
      "Epoch [21/100], Training Loss: 10.6796, Validation Loss: 21.2156\n",
      "Epoch [22/100], Training Loss: 13.6797, Validation Loss: 20.9623\n",
      "Epoch [23/100], Training Loss: 8.5504, Validation Loss: 20.9879\n",
      "Epoch [24/100], Training Loss: 13.5325, Validation Loss: 20.7040\n",
      "Epoch [25/100], Training Loss: 9.7970, Validation Loss: 20.5276\n",
      "Epoch [26/100], Training Loss: 11.7466, Validation Loss: 20.3880\n",
      "Epoch [27/100], Training Loss: 8.2365, Validation Loss: 20.1612\n",
      "Epoch [28/100], Training Loss: 8.6970, Validation Loss: 19.9603\n",
      "Epoch [29/100], Training Loss: 9.8546, Validation Loss: 20.0479\n",
      "Epoch [30/100], Training Loss: 11.6147, Validation Loss: 19.6964\n",
      "Epoch [31/100], Training Loss: 6.7720, Validation Loss: 19.7109\n",
      "Epoch [32/100], Training Loss: 11.3270, Validation Loss: 19.5927\n",
      "Epoch [33/100], Training Loss: 7.2843, Validation Loss: 19.4262\n",
      "Epoch [34/100], Training Loss: 9.0994, Validation Loss: 19.3079\n",
      "Epoch [35/100], Training Loss: 9.4272, Validation Loss: 19.2973\n",
      "Epoch [36/100], Training Loss: 11.8339, Validation Loss: 19.1030\n",
      "Epoch [37/100], Training Loss: 8.9318, Validation Loss: 18.9812\n",
      "Epoch [38/100], Training Loss: 8.4341, Validation Loss: 19.0484\n",
      "Epoch [39/100], Training Loss: 8.1728, Validation Loss: 18.8310\n",
      "Epoch [40/100], Training Loss: 7.6132, Validation Loss: 18.7607\n",
      "Epoch [41/100], Training Loss: 6.7948, Validation Loss: 18.6894\n",
      "Epoch [42/100], Training Loss: 9.4550, Validation Loss: 18.6222\n",
      "Epoch [43/100], Training Loss: 9.5797, Validation Loss: 18.5320\n",
      "Epoch [44/100], Training Loss: 10.5741, Validation Loss: 18.4966\n",
      "Epoch [45/100], Training Loss: 9.6954, Validation Loss: 18.3206\n",
      "Epoch [46/100], Training Loss: 8.6640, Validation Loss: 18.2751\n",
      "Epoch [47/100], Training Loss: 9.5441, Validation Loss: 18.2056\n",
      "Epoch [48/100], Training Loss: 10.3534, Validation Loss: 18.0919\n",
      "Epoch [49/100], Training Loss: 11.9230, Validation Loss: 18.0235\n",
      "Epoch [50/100], Training Loss: 7.7282, Validation Loss: 17.9677\n",
      "Epoch [51/100], Training Loss: 9.0870, Validation Loss: 17.9513\n",
      "Epoch [52/100], Training Loss: 8.4636, Validation Loss: 17.9982\n",
      "Epoch [53/100], Training Loss: 7.4482, Validation Loss: 17.8298\n",
      "Epoch [54/100], Training Loss: 7.7772, Validation Loss: 17.7668\n",
      "Epoch [55/100], Training Loss: 9.7657, Validation Loss: 17.6443\n",
      "Epoch [56/100], Training Loss: 9.6133, Validation Loss: 17.6222\n",
      "Epoch [57/100], Training Loss: 8.1810, Validation Loss: 17.5610\n",
      "Epoch [58/100], Training Loss: 7.3119, Validation Loss: 17.5689\n",
      "Epoch [59/100], Training Loss: 9.0872, Validation Loss: 17.4868\n",
      "Epoch [60/100], Training Loss: 7.4174, Validation Loss: 17.4531\n",
      "Epoch [61/100], Training Loss: 13.5966, Validation Loss: 17.3401\n",
      "Epoch [62/100], Training Loss: 9.1411, Validation Loss: 17.3302\n",
      "Epoch [63/100], Training Loss: 7.9833, Validation Loss: 17.3118\n",
      "Epoch [64/100], Training Loss: 12.0143, Validation Loss: 17.2124\n",
      "Epoch [65/100], Training Loss: 8.8841, Validation Loss: 17.1829\n",
      "Epoch [66/100], Training Loss: 9.1327, Validation Loss: 17.2442\n",
      "Epoch [67/100], Training Loss: 8.8218, Validation Loss: 17.0694\n",
      "Epoch [68/100], Training Loss: 7.8346, Validation Loss: 17.0605\n",
      "Epoch [69/100], Training Loss: 9.3156, Validation Loss: 17.0458\n",
      "Epoch [70/100], Training Loss: 7.4199, Validation Loss: 17.0834\n",
      "Epoch [71/100], Training Loss: 8.4047, Validation Loss: 16.9903\n",
      "Epoch [72/100], Training Loss: 6.7025, Validation Loss: 16.9663\n",
      "Epoch [73/100], Training Loss: 7.2358, Validation Loss: 16.9317\n",
      "Epoch [74/100], Training Loss: 5.8552, Validation Loss: 16.9122\n",
      "Epoch [75/100], Training Loss: 7.1229, Validation Loss: 16.8824\n",
      "Epoch [76/100], Training Loss: 6.6876, Validation Loss: 16.8420\n",
      "Epoch [77/100], Training Loss: 10.7578, Validation Loss: 16.9383\n",
      "Epoch [78/100], Training Loss: 10.1758, Validation Loss: 16.8473\n",
      "Epoch [79/100], Training Loss: 10.5942, Validation Loss: 16.7758\n",
      "Epoch [80/100], Training Loss: 6.7891, Validation Loss: 16.7399\n",
      "Epoch [81/100], Training Loss: 6.4278, Validation Loss: 16.7182\n",
      "Epoch [82/100], Training Loss: 8.3782, Validation Loss: 16.7094\n",
      "Epoch [83/100], Training Loss: 7.0673, Validation Loss: 16.7043\n",
      "Epoch [84/100], Training Loss: 7.0172, Validation Loss: 16.6082\n",
      "Epoch [85/100], Training Loss: 6.5530, Validation Loss: 16.7282\n",
      "Epoch [86/100], Training Loss: 6.4342, Validation Loss: 16.6084\n",
      "Epoch [87/100], Training Loss: 9.5179, Validation Loss: 16.6631\n",
      "Epoch [88/100], Training Loss: 9.1907, Validation Loss: 16.5829\n",
      "Epoch [89/100], Training Loss: 7.8156, Validation Loss: 16.5763\n",
      "Epoch [90/100], Training Loss: 8.1972, Validation Loss: 16.6060\n",
      "Epoch [91/100], Training Loss: 6.2632, Validation Loss: 16.5818\n",
      "Epoch [92/100], Training Loss: 7.0813, Validation Loss: 16.5646\n",
      "Epoch [93/100], Training Loss: 5.1357, Validation Loss: 16.5829\n",
      "Epoch [94/100], Training Loss: 7.6917, Validation Loss: 16.5705\n",
      "Epoch [95/100], Training Loss: 6.1378, Validation Loss: 16.5314\n",
      "Epoch [96/100], Training Loss: 7.3221, Validation Loss: 16.5141\n",
      "Epoch [97/100], Training Loss: 9.0691, Validation Loss: 16.4840\n",
      "Epoch [98/100], Training Loss: 9.1940, Validation Loss: 16.4371\n",
      "Epoch [99/100], Training Loss: 8.5182, Validation Loss: 16.5062\n",
      "Epoch [100/100], Training Loss: 9.2688, Validation Loss: 16.5053\n",
      "F1-Score: 0.9873, Optimal Threshold: 13.5819\n",
      "Epoch [1/100], Training Loss: 70.0740, Validation Loss: 123.1837\n",
      "Epoch [2/100], Training Loss: 51.0480, Validation Loss: 90.9752\n",
      "Epoch [3/100], Training Loss: 25.5061, Validation Loss: 64.6823\n",
      "Epoch [4/100], Training Loss: 24.7176, Validation Loss: 45.5523\n",
      "Epoch [5/100], Training Loss: 18.5431, Validation Loss: 37.0376\n",
      "Epoch [6/100], Training Loss: 15.4634, Validation Loss: 34.2883\n",
      "Epoch [7/100], Training Loss: 14.0555, Validation Loss: 33.3169\n",
      "Epoch [8/100], Training Loss: 12.3066, Validation Loss: 32.5110\n",
      "Epoch [9/100], Training Loss: 12.8239, Validation Loss: 31.4791\n",
      "Epoch [10/100], Training Loss: 17.3300, Validation Loss: 30.2915\n",
      "Epoch [11/100], Training Loss: 13.7278, Validation Loss: 28.8294\n",
      "Epoch [12/100], Training Loss: 9.0015, Validation Loss: 27.4100\n",
      "Epoch [13/100], Training Loss: 13.6443, Validation Loss: 26.2501\n",
      "Epoch [14/100], Training Loss: 10.6327, Validation Loss: 24.6934\n",
      "Epoch [15/100], Training Loss: 9.8534, Validation Loss: 23.5657\n",
      "Epoch [16/100], Training Loss: 11.1484, Validation Loss: 22.7606\n",
      "Epoch [17/100], Training Loss: 9.3332, Validation Loss: 21.9633\n",
      "Epoch [18/100], Training Loss: 8.0274, Validation Loss: 21.5666\n",
      "Epoch [19/100], Training Loss: 7.7623, Validation Loss: 21.2396\n",
      "Epoch [20/100], Training Loss: 9.4875, Validation Loss: 20.8525\n",
      "Epoch [21/100], Training Loss: 9.0407, Validation Loss: 20.4861\n",
      "Epoch [22/100], Training Loss: 9.2566, Validation Loss: 20.4547\n",
      "Epoch [23/100], Training Loss: 7.6177, Validation Loss: 20.3133\n",
      "Epoch [24/100], Training Loss: 9.4388, Validation Loss: 20.0183\n",
      "Epoch [25/100], Training Loss: 6.2801, Validation Loss: 19.7576\n",
      "Epoch [26/100], Training Loss: 6.7502, Validation Loss: 19.5872\n",
      "Epoch [27/100], Training Loss: 8.6189, Validation Loss: 19.3384\n",
      "Epoch [28/100], Training Loss: 7.1521, Validation Loss: 19.3574\n",
      "Epoch [29/100], Training Loss: 8.1309, Validation Loss: 19.1189\n",
      "Epoch [30/100], Training Loss: 6.0678, Validation Loss: 18.9009\n",
      "Epoch [31/100], Training Loss: 5.9562, Validation Loss: 18.7491\n",
      "Epoch [32/100], Training Loss: 7.0537, Validation Loss: 18.6553\n",
      "Epoch [33/100], Training Loss: 6.7182, Validation Loss: 18.6384\n",
      "Epoch [34/100], Training Loss: 6.2324, Validation Loss: 18.3006\n",
      "Epoch [35/100], Training Loss: 6.9541, Validation Loss: 18.2015\n",
      "Epoch [36/100], Training Loss: 4.7703, Validation Loss: 18.1485\n",
      "Epoch [37/100], Training Loss: 6.7603, Validation Loss: 17.9475\n",
      "Epoch [38/100], Training Loss: 6.2658, Validation Loss: 17.9343\n",
      "Epoch [39/100], Training Loss: 8.5964, Validation Loss: 17.8323\n",
      "Epoch [40/100], Training Loss: 8.4976, Validation Loss: 17.6186\n",
      "Epoch [41/100], Training Loss: 8.7166, Validation Loss: 17.4671\n",
      "Epoch [42/100], Training Loss: 6.6228, Validation Loss: 17.5495\n",
      "Epoch [43/100], Training Loss: 7.2720, Validation Loss: 17.3299\n",
      "Epoch [44/100], Training Loss: 5.6910, Validation Loss: 17.2758\n",
      "Epoch [45/100], Training Loss: 6.4552, Validation Loss: 17.1488\n",
      "Epoch [46/100], Training Loss: 8.4456, Validation Loss: 17.1309\n",
      "Epoch [47/100], Training Loss: 4.3806, Validation Loss: 17.0743\n",
      "Epoch [48/100], Training Loss: 7.7400, Validation Loss: 16.9375\n",
      "Epoch [49/100], Training Loss: 7.5666, Validation Loss: 16.8319\n",
      "Epoch [50/100], Training Loss: 5.5321, Validation Loss: 16.8157\n",
      "Epoch [51/100], Training Loss: 5.7192, Validation Loss: 16.5913\n",
      "Epoch [52/100], Training Loss: 7.0573, Validation Loss: 16.6741\n",
      "Epoch [53/100], Training Loss: 6.9779, Validation Loss: 16.4918\n",
      "Epoch [54/100], Training Loss: 7.9549, Validation Loss: 16.4708\n",
      "Epoch [55/100], Training Loss: 6.7574, Validation Loss: 16.4388\n",
      "Epoch [56/100], Training Loss: 6.5514, Validation Loss: 16.3905\n",
      "Epoch [57/100], Training Loss: 6.4995, Validation Loss: 16.2551\n",
      "Epoch [58/100], Training Loss: 5.5118, Validation Loss: 16.2321\n",
      "Epoch [59/100], Training Loss: 6.2397, Validation Loss: 16.2283\n",
      "Epoch [60/100], Training Loss: 6.1066, Validation Loss: 16.0877\n",
      "Epoch [61/100], Training Loss: 3.7515, Validation Loss: 16.0667\n",
      "Epoch [62/100], Training Loss: 7.5326, Validation Loss: 16.0000\n",
      "Epoch [63/100], Training Loss: 6.9395, Validation Loss: 15.9771\n",
      "Epoch [64/100], Training Loss: 4.6377, Validation Loss: 15.9455\n",
      "Epoch [65/100], Training Loss: 5.0789, Validation Loss: 15.8382\n",
      "Epoch [66/100], Training Loss: 17.9256, Validation Loss: 15.8610\n",
      "Epoch [67/100], Training Loss: 5.7995, Validation Loss: 15.8119\n",
      "Epoch [68/100], Training Loss: 5.6815, Validation Loss: 15.7337\n",
      "Epoch [69/100], Training Loss: 5.6363, Validation Loss: 15.7804\n",
      "Epoch [70/100], Training Loss: 5.2047, Validation Loss: 15.6726\n",
      "Epoch [71/100], Training Loss: 5.1432, Validation Loss: 15.6600\n",
      "Epoch [72/100], Training Loss: 4.7240, Validation Loss: 15.6712\n",
      "Epoch [73/100], Training Loss: 7.3579, Validation Loss: 15.6153\n",
      "Epoch [74/100], Training Loss: 5.2813, Validation Loss: 15.5760\n",
      "Epoch [75/100], Training Loss: 3.6728, Validation Loss: 15.5442\n",
      "Epoch [76/100], Training Loss: 5.2981, Validation Loss: 15.4765\n",
      "Epoch [77/100], Training Loss: 4.4776, Validation Loss: 15.5119\n",
      "Epoch [78/100], Training Loss: 6.1394, Validation Loss: 15.4917\n",
      "Epoch [79/100], Training Loss: 4.9045, Validation Loss: 15.4477\n",
      "Epoch [80/100], Training Loss: 4.5776, Validation Loss: 15.4495\n",
      "Epoch [81/100], Training Loss: 3.5441, Validation Loss: 15.3795\n",
      "Epoch [82/100], Training Loss: 4.0153, Validation Loss: 15.3436\n",
      "Epoch [83/100], Training Loss: 6.1171, Validation Loss: 15.3480\n",
      "Epoch [84/100], Training Loss: 4.6119, Validation Loss: 15.3671\n",
      "Epoch [85/100], Training Loss: 4.4022, Validation Loss: 15.2751\n",
      "Epoch [86/100], Training Loss: 6.8036, Validation Loss: 15.3224\n",
      "Epoch [87/100], Training Loss: 4.2232, Validation Loss: 15.2352\n",
      "Epoch [88/100], Training Loss: 4.1326, Validation Loss: 15.2269\n",
      "Epoch [89/100], Training Loss: 5.8580, Validation Loss: 15.2290\n",
      "Epoch [90/100], Training Loss: 5.9052, Validation Loss: 15.2215\n",
      "Epoch [91/100], Training Loss: 5.5974, Validation Loss: 15.2354\n",
      "Epoch [92/100], Training Loss: 4.1235, Validation Loss: 15.1896\n",
      "Epoch [93/100], Training Loss: 3.5357, Validation Loss: 15.1815\n",
      "Epoch [94/100], Training Loss: 5.1511, Validation Loss: 15.1902\n",
      "Epoch [95/100], Training Loss: 5.0057, Validation Loss: 15.1651\n",
      "Epoch [96/100], Training Loss: 5.2378, Validation Loss: 15.1706\n",
      "Epoch [97/100], Training Loss: 5.8091, Validation Loss: 15.1542\n",
      "Epoch [98/100], Training Loss: 4.3269, Validation Loss: 15.1202\n",
      "Epoch [99/100], Training Loss: 5.2335, Validation Loss: 15.1298\n",
      "Epoch [100/100], Training Loss: 4.2563, Validation Loss: 15.0879\n",
      "F1-Score: 0.9247, Optimal Threshold: 11.7947\n",
      "Epoch [1/100], Training Loss: 86.7741, Validation Loss: 127.8661\n",
      "Epoch [2/100], Training Loss: 63.5195, Validation Loss: 97.6039\n",
      "Epoch [3/100], Training Loss: 47.4181, Validation Loss: 73.2448\n",
      "Epoch [4/100], Training Loss: 34.8085, Validation Loss: 54.1165\n",
      "Epoch [5/100], Training Loss: 28.3093, Validation Loss: 40.4210\n",
      "Epoch [6/100], Training Loss: 18.5500, Validation Loss: 32.8951\n",
      "Epoch [7/100], Training Loss: 15.7289, Validation Loss: 29.8037\n",
      "Epoch [8/100], Training Loss: 13.2987, Validation Loss: 27.9383\n",
      "Epoch [9/100], Training Loss: 12.7152, Validation Loss: 27.0519\n",
      "Epoch [10/100], Training Loss: 13.7892, Validation Loss: 25.6527\n",
      "Epoch [11/100], Training Loss: 11.3375, Validation Loss: 24.5445\n",
      "Epoch [12/100], Training Loss: 14.3987, Validation Loss: 23.3495\n",
      "Epoch [13/100], Training Loss: 12.1613, Validation Loss: 22.2812\n",
      "Epoch [14/100], Training Loss: 17.8000, Validation Loss: 21.3628\n",
      "Epoch [15/100], Training Loss: 11.9925, Validation Loss: 20.4933\n",
      "Epoch [16/100], Training Loss: 12.1094, Validation Loss: 20.0657\n",
      "Epoch [17/100], Training Loss: 7.4676, Validation Loss: 19.3927\n",
      "Epoch [18/100], Training Loss: 11.3956, Validation Loss: 18.9307\n",
      "Epoch [19/100], Training Loss: 18.8132, Validation Loss: 18.7732\n",
      "Epoch [20/100], Training Loss: 8.1232, Validation Loss: 18.4240\n",
      "Epoch [21/100], Training Loss: 8.9750, Validation Loss: 18.1208\n",
      "Epoch [22/100], Training Loss: 7.8770, Validation Loss: 18.0001\n",
      "Epoch [23/100], Training Loss: 6.6744, Validation Loss: 17.5620\n",
      "Epoch [24/100], Training Loss: 7.2482, Validation Loss: 17.6244\n",
      "Epoch [25/100], Training Loss: 9.5675, Validation Loss: 17.3158\n",
      "Epoch [26/100], Training Loss: 6.9376, Validation Loss: 17.1078\n",
      "Epoch [27/100], Training Loss: 6.7057, Validation Loss: 16.9806\n",
      "Epoch [28/100], Training Loss: 6.1672, Validation Loss: 16.9737\n",
      "Epoch [29/100], Training Loss: 8.6131, Validation Loss: 16.6316\n",
      "Epoch [30/100], Training Loss: 5.9830, Validation Loss: 16.5071\n",
      "Epoch [31/100], Training Loss: 7.5928, Validation Loss: 16.4490\n",
      "Epoch [32/100], Training Loss: 7.0236, Validation Loss: 16.3318\n",
      "Epoch [33/100], Training Loss: 7.4355, Validation Loss: 16.1789\n",
      "Epoch [34/100], Training Loss: 6.3833, Validation Loss: 16.0341\n",
      "Epoch [35/100], Training Loss: 5.3779, Validation Loss: 15.8646\n",
      "Epoch [36/100], Training Loss: 8.1090, Validation Loss: 15.7130\n",
      "Epoch [37/100], Training Loss: 10.3900, Validation Loss: 15.5218\n",
      "Epoch [38/100], Training Loss: 10.3029, Validation Loss: 15.4614\n",
      "Epoch [39/100], Training Loss: 7.1418, Validation Loss: 15.3728\n",
      "Epoch [40/100], Training Loss: 8.8913, Validation Loss: 15.2375\n",
      "Epoch [41/100], Training Loss: 10.6270, Validation Loss: 15.0966\n",
      "Epoch [42/100], Training Loss: 9.1990, Validation Loss: 15.1543\n",
      "Epoch [43/100], Training Loss: 6.2362, Validation Loss: 15.0138\n",
      "Epoch [44/100], Training Loss: 9.4591, Validation Loss: 14.9007\n",
      "Epoch [45/100], Training Loss: 8.5926, Validation Loss: 14.8179\n",
      "Epoch [46/100], Training Loss: 8.4657, Validation Loss: 14.6439\n",
      "Epoch [47/100], Training Loss: 7.2508, Validation Loss: 14.5785\n",
      "Epoch [48/100], Training Loss: 6.5951, Validation Loss: 14.5704\n",
      "Epoch [49/100], Training Loss: 7.7766, Validation Loss: 14.5018\n",
      "Epoch [50/100], Training Loss: 5.0853, Validation Loss: 14.3458\n",
      "Epoch [51/100], Training Loss: 6.6874, Validation Loss: 14.2469\n",
      "Epoch [52/100], Training Loss: 4.9144, Validation Loss: 14.3398\n",
      "Epoch [53/100], Training Loss: 5.2013, Validation Loss: 14.1460\n",
      "Epoch [54/100], Training Loss: 6.3769, Validation Loss: 14.1546\n",
      "Epoch [55/100], Training Loss: 4.9959, Validation Loss: 14.1242\n",
      "Epoch [56/100], Training Loss: 10.1252, Validation Loss: 14.0231\n",
      "Epoch [57/100], Training Loss: 5.2379, Validation Loss: 13.8861\n",
      "Epoch [58/100], Training Loss: 7.1974, Validation Loss: 13.8698\n",
      "Epoch [59/100], Training Loss: 4.7756, Validation Loss: 13.8280\n",
      "Epoch [60/100], Training Loss: 4.8651, Validation Loss: 13.8090\n",
      "Epoch [61/100], Training Loss: 6.4309, Validation Loss: 13.7398\n",
      "Epoch [62/100], Training Loss: 7.2941, Validation Loss: 13.6861\n",
      "Epoch [63/100], Training Loss: 6.1228, Validation Loss: 13.5981\n",
      "Epoch [64/100], Training Loss: 7.0995, Validation Loss: 13.5282\n",
      "Epoch [65/100], Training Loss: 7.6778, Validation Loss: 13.5090\n",
      "Epoch [66/100], Training Loss: 7.7900, Validation Loss: 13.4980\n",
      "Epoch [67/100], Training Loss: 6.0086, Validation Loss: 13.4891\n",
      "Epoch [68/100], Training Loss: 5.7521, Validation Loss: 13.4120\n",
      "Epoch [69/100], Training Loss: 5.3833, Validation Loss: 13.4344\n",
      "Epoch [70/100], Training Loss: 6.6787, Validation Loss: 13.3172\n",
      "Epoch [71/100], Training Loss: 4.0496, Validation Loss: 13.3544\n",
      "Epoch [72/100], Training Loss: 6.4814, Validation Loss: 13.3199\n",
      "Epoch [73/100], Training Loss: 7.0339, Validation Loss: 13.2334\n",
      "Epoch [74/100], Training Loss: 4.7056, Validation Loss: 13.2749\n",
      "Epoch [75/100], Training Loss: 5.2393, Validation Loss: 13.1832\n",
      "Epoch [76/100], Training Loss: 6.1289, Validation Loss: 13.2336\n",
      "Epoch [77/100], Training Loss: 4.1869, Validation Loss: 13.1957\n",
      "Epoch [78/100], Training Loss: 5.4220, Validation Loss: 13.1981\n",
      "Epoch [79/100], Training Loss: 5.8439, Validation Loss: 13.0756\n",
      "Epoch [80/100], Training Loss: 5.3482, Validation Loss: 13.1154\n",
      "Epoch [81/100], Training Loss: 7.4850, Validation Loss: 13.1267\n",
      "Epoch [82/100], Training Loss: 6.5970, Validation Loss: 13.0094\n",
      "Epoch [83/100], Training Loss: 7.1357, Validation Loss: 13.0445\n",
      "Epoch [84/100], Training Loss: 6.2960, Validation Loss: 13.0017\n",
      "Epoch [85/100], Training Loss: 7.2499, Validation Loss: 13.0317\n",
      "Epoch [86/100], Training Loss: 5.6695, Validation Loss: 12.9882\n",
      "Epoch [87/100], Training Loss: 7.5566, Validation Loss: 12.9200\n",
      "Epoch [88/100], Training Loss: 6.7862, Validation Loss: 12.9335\n",
      "Epoch [89/100], Training Loss: 6.8980, Validation Loss: 12.9148\n",
      "Epoch [90/100], Training Loss: 13.3317, Validation Loss: 12.8983\n",
      "Epoch [91/100], Training Loss: 6.0162, Validation Loss: 12.9593\n",
      "Epoch [92/100], Training Loss: 3.7862, Validation Loss: 12.8975\n",
      "Epoch [93/100], Training Loss: 6.2510, Validation Loss: 12.9206\n",
      "Epoch [94/100], Training Loss: 4.8572, Validation Loss: 12.8451\n",
      "Epoch [95/100], Training Loss: 11.4539, Validation Loss: 12.8484\n",
      "Epoch [96/100], Training Loss: 4.1641, Validation Loss: 12.8301\n",
      "Epoch [97/100], Training Loss: 5.4092, Validation Loss: 12.8339\n",
      "Epoch [98/100], Training Loss: 4.5912, Validation Loss: 12.8293\n",
      "Epoch [99/100], Training Loss: 4.5793, Validation Loss: 12.8150\n",
      "Epoch [100/100], Training Loss: 6.0698, Validation Loss: 12.7684\n",
      "F1-Score: 0.7600, Optimal Threshold: 9.9180\n",
      "Epoch [1/100], Training Loss: 60.4084, Validation Loss: 117.4255\n",
      "Epoch [2/100], Training Loss: 46.0338, Validation Loss: 84.4818\n",
      "Epoch [3/100], Training Loss: 30.6409, Validation Loss: 57.6098\n",
      "Epoch [4/100], Training Loss: 19.5685, Validation Loss: 39.4504\n",
      "Epoch [5/100], Training Loss: 17.3582, Validation Loss: 32.6012\n",
      "Epoch [6/100], Training Loss: 15.7277, Validation Loss: 30.7376\n",
      "Epoch [7/100], Training Loss: 14.5740, Validation Loss: 29.8368\n",
      "Epoch [8/100], Training Loss: 12.9885, Validation Loss: 28.9807\n",
      "Epoch [9/100], Training Loss: 9.5932, Validation Loss: 27.6871\n",
      "Epoch [10/100], Training Loss: 16.1279, Validation Loss: 26.4318\n",
      "Epoch [11/100], Training Loss: 17.4285, Validation Loss: 24.9806\n",
      "Epoch [12/100], Training Loss: 8.7163, Validation Loss: 23.4903\n",
      "Epoch [13/100], Training Loss: 9.0474, Validation Loss: 22.5192\n",
      "Epoch [14/100], Training Loss: 10.5056, Validation Loss: 21.8367\n",
      "Epoch [15/100], Training Loss: 10.7813, Validation Loss: 21.1104\n",
      "Epoch [16/100], Training Loss: 9.4700, Validation Loss: 20.7066\n",
      "Epoch [17/100], Training Loss: 6.1000, Validation Loss: 20.4577\n",
      "Epoch [18/100], Training Loss: 10.2041, Validation Loss: 20.0753\n",
      "Epoch [19/100], Training Loss: 8.1669, Validation Loss: 19.7988\n",
      "Epoch [20/100], Training Loss: 8.0580, Validation Loss: 19.6138\n",
      "Epoch [21/100], Training Loss: 7.3988, Validation Loss: 19.5577\n",
      "Epoch [22/100], Training Loss: 7.9591, Validation Loss: 19.0551\n",
      "Epoch [23/100], Training Loss: 12.6477, Validation Loss: 18.8241\n",
      "Epoch [24/100], Training Loss: 6.1565, Validation Loss: 18.7163\n",
      "Epoch [25/100], Training Loss: 7.7028, Validation Loss: 18.4569\n",
      "Epoch [26/100], Training Loss: 7.2162, Validation Loss: 18.3995\n",
      "Epoch [27/100], Training Loss: 7.6910, Validation Loss: 18.0563\n",
      "Epoch [28/100], Training Loss: 8.2907, Validation Loss: 17.8976\n",
      "Epoch [29/100], Training Loss: 8.8114, Validation Loss: 17.8259\n",
      "Epoch [30/100], Training Loss: 10.6396, Validation Loss: 17.7165\n",
      "Epoch [31/100], Training Loss: 7.0018, Validation Loss: 17.5646\n",
      "Epoch [32/100], Training Loss: 6.4205, Validation Loss: 17.3435\n",
      "Epoch [33/100], Training Loss: 5.4195, Validation Loss: 17.1817\n",
      "Epoch [34/100], Training Loss: 5.2877, Validation Loss: 17.1091\n",
      "Epoch [35/100], Training Loss: 6.6342, Validation Loss: 17.0116\n",
      "Epoch [36/100], Training Loss: 6.7355, Validation Loss: 16.8390\n",
      "Epoch [37/100], Training Loss: 5.5740, Validation Loss: 16.7410\n",
      "Epoch [38/100], Training Loss: 7.2010, Validation Loss: 16.5934\n",
      "Epoch [39/100], Training Loss: 6.5355, Validation Loss: 16.5262\n",
      "Epoch [40/100], Training Loss: 7.6527, Validation Loss: 16.4152\n",
      "Epoch [41/100], Training Loss: 7.5057, Validation Loss: 16.2946\n",
      "Epoch [42/100], Training Loss: 6.4298, Validation Loss: 16.1978\n",
      "Epoch [43/100], Training Loss: 6.8811, Validation Loss: 16.1146\n",
      "Epoch [44/100], Training Loss: 7.1039, Validation Loss: 15.9385\n",
      "Epoch [45/100], Training Loss: 7.0737, Validation Loss: 15.9345\n",
      "Epoch [46/100], Training Loss: 5.6407, Validation Loss: 15.8468\n",
      "Epoch [47/100], Training Loss: 8.8612, Validation Loss: 15.7465\n",
      "Epoch [48/100], Training Loss: 7.3659, Validation Loss: 15.7307\n",
      "Epoch [49/100], Training Loss: 5.7609, Validation Loss: 15.5352\n",
      "Epoch [50/100], Training Loss: 5.8154, Validation Loss: 15.5527\n",
      "Epoch [51/100], Training Loss: 9.2964, Validation Loss: 15.5237\n",
      "Epoch [52/100], Training Loss: 9.7026, Validation Loss: 15.4466\n",
      "Epoch [53/100], Training Loss: 18.2135, Validation Loss: 15.3566\n",
      "Epoch [54/100], Training Loss: 4.3665, Validation Loss: 15.2805\n",
      "Epoch [55/100], Training Loss: 3.8115, Validation Loss: 15.3142\n",
      "Epoch [56/100], Training Loss: 6.5853, Validation Loss: 15.1934\n",
      "Epoch [57/100], Training Loss: 6.3343, Validation Loss: 15.1157\n",
      "Epoch [58/100], Training Loss: 6.1524, Validation Loss: 15.0956\n",
      "Epoch [59/100], Training Loss: 4.8329, Validation Loss: 15.0085\n",
      "Epoch [60/100], Training Loss: 8.3847, Validation Loss: 14.9695\n",
      "Epoch [61/100], Training Loss: 5.8018, Validation Loss: 14.9088\n",
      "Epoch [62/100], Training Loss: 5.3045, Validation Loss: 14.9756\n",
      "Epoch [63/100], Training Loss: 5.9234, Validation Loss: 14.9182\n",
      "Epoch [64/100], Training Loss: 4.9113, Validation Loss: 14.9325\n",
      "Epoch [65/100], Training Loss: 8.5918, Validation Loss: 14.8796\n",
      "Epoch [66/100], Training Loss: 4.8699, Validation Loss: 14.8123\n",
      "Epoch [67/100], Training Loss: 8.1457, Validation Loss: 14.8221\n",
      "Epoch [68/100], Training Loss: 6.1955, Validation Loss: 14.7417\n",
      "Epoch [69/100], Training Loss: 5.3264, Validation Loss: 14.6918\n",
      "Epoch [70/100], Training Loss: 5.7303, Validation Loss: 14.6966\n",
      "Epoch [71/100], Training Loss: 5.0380, Validation Loss: 14.6570\n",
      "Epoch [72/100], Training Loss: 3.8157, Validation Loss: 14.6688\n",
      "Epoch [73/100], Training Loss: 5.5745, Validation Loss: 14.6426\n",
      "Epoch [74/100], Training Loss: 4.1235, Validation Loss: 14.6447\n",
      "Epoch [75/100], Training Loss: 6.1939, Validation Loss: 14.6042\n",
      "Epoch [76/100], Training Loss: 7.6730, Validation Loss: 14.5977\n",
      "Epoch [77/100], Training Loss: 6.3955, Validation Loss: 14.5703\n",
      "Epoch [78/100], Training Loss: 3.5290, Validation Loss: 14.5111\n",
      "Epoch [79/100], Training Loss: 6.3234, Validation Loss: 14.5342\n",
      "Epoch [80/100], Training Loss: 4.4731, Validation Loss: 14.4838\n",
      "Epoch [81/100], Training Loss: 4.5221, Validation Loss: 14.4974\n",
      "Epoch [82/100], Training Loss: 6.2152, Validation Loss: 14.5182\n",
      "Epoch [83/100], Training Loss: 4.8173, Validation Loss: 14.4706\n",
      "Epoch [84/100], Training Loss: 6.8027, Validation Loss: 14.4623\n",
      "Epoch [85/100], Training Loss: 4.8508, Validation Loss: 14.4625\n",
      "Epoch [86/100], Training Loss: 7.1333, Validation Loss: 14.4789\n",
      "Epoch [87/100], Training Loss: 8.6240, Validation Loss: 14.4623\n",
      "Epoch [88/100], Training Loss: 5.4607, Validation Loss: 14.3869\n",
      "Epoch [89/100], Training Loss: 6.0021, Validation Loss: 14.3888\n",
      "Epoch [90/100], Training Loss: 6.2123, Validation Loss: 14.3629\n",
      "Epoch [91/100], Training Loss: 7.4845, Validation Loss: 14.3935\n",
      "Epoch [92/100], Training Loss: 4.2179, Validation Loss: 14.4063\n",
      "Epoch [93/100], Training Loss: 4.0251, Validation Loss: 14.3446\n",
      "Epoch [94/100], Training Loss: 6.8013, Validation Loss: 14.3795\n",
      "Epoch [95/100], Training Loss: 7.7962, Validation Loss: 14.3002\n",
      "Epoch [96/100], Training Loss: 4.5474, Validation Loss: 14.3109\n",
      "Epoch [97/100], Training Loss: 4.6161, Validation Loss: 14.3349\n",
      "Epoch [98/100], Training Loss: 3.7179, Validation Loss: 14.3337\n",
      "Epoch [99/100], Training Loss: 5.2316, Validation Loss: 14.3427\n",
      "Epoch [100/100], Training Loss: 4.7421, Validation Loss: 14.3230\n",
      "F1-Score: 0.8348, Optimal Threshold: 11.9859\n",
      "Epoch [1/100], Training Loss: 57.1553, Validation Loss: 129.1702\n",
      "Epoch [2/100], Training Loss: 42.3414, Validation Loss: 101.5808\n",
      "Epoch [3/100], Training Loss: 30.5513, Validation Loss: 79.7955\n",
      "Epoch [4/100], Training Loss: 23.9347, Validation Loss: 61.3534\n",
      "Epoch [5/100], Training Loss: 14.0227, Validation Loss: 47.2392\n",
      "Epoch [6/100], Training Loss: 12.3064, Validation Loss: 39.7779\n",
      "Epoch [7/100], Training Loss: 12.2825, Validation Loss: 36.5770\n",
      "Epoch [8/100], Training Loss: 12.4861, Validation Loss: 35.1621\n",
      "Epoch [9/100], Training Loss: 9.5628, Validation Loss: 33.6247\n",
      "Epoch [10/100], Training Loss: 9.2477, Validation Loss: 32.7627\n",
      "Epoch [11/100], Training Loss: 9.3466, Validation Loss: 31.4994\n",
      "Epoch [12/100], Training Loss: 7.2469, Validation Loss: 30.5202\n",
      "Epoch [13/100], Training Loss: 7.1154, Validation Loss: 29.7958\n",
      "Epoch [14/100], Training Loss: 7.9553, Validation Loss: 28.2782\n",
      "Epoch [15/100], Training Loss: 7.8855, Validation Loss: 27.2517\n",
      "Epoch [16/100], Training Loss: 7.8825, Validation Loss: 26.3669\n",
      "Epoch [17/100], Training Loss: 5.8353, Validation Loss: 25.3345\n",
      "Epoch [18/100], Training Loss: 6.6258, Validation Loss: 24.5666\n",
      "Epoch [19/100], Training Loss: 10.6281, Validation Loss: 23.7851\n",
      "Epoch [20/100], Training Loss: 5.7227, Validation Loss: 23.6232\n",
      "Epoch [21/100], Training Loss: 6.4186, Validation Loss: 23.1954\n",
      "Epoch [22/100], Training Loss: 6.3885, Validation Loss: 22.6976\n",
      "Epoch [23/100], Training Loss: 4.2631, Validation Loss: 22.5739\n",
      "Epoch [24/100], Training Loss: 3.7666, Validation Loss: 22.2423\n",
      "Epoch [25/100], Training Loss: 7.2832, Validation Loss: 22.1602\n",
      "Epoch [26/100], Training Loss: 5.8487, Validation Loss: 21.8783\n",
      "Epoch [27/100], Training Loss: 6.0104, Validation Loss: 21.6108\n",
      "Epoch [28/100], Training Loss: 4.9218, Validation Loss: 21.6954\n",
      "Epoch [29/100], Training Loss: 3.6411, Validation Loss: 21.4026\n",
      "Epoch [30/100], Training Loss: 4.9884, Validation Loss: 21.1771\n",
      "Epoch [31/100], Training Loss: 5.9981, Validation Loss: 20.9927\n",
      "Epoch [32/100], Training Loss: 3.5791, Validation Loss: 21.0406\n",
      "Epoch [33/100], Training Loss: 4.8515, Validation Loss: 20.7460\n",
      "Epoch [34/100], Training Loss: 4.0720, Validation Loss: 20.7448\n",
      "Epoch [35/100], Training Loss: 5.3267, Validation Loss: 20.6082\n",
      "Epoch [36/100], Training Loss: 5.2332, Validation Loss: 20.5503\n",
      "Epoch [37/100], Training Loss: 4.8388, Validation Loss: 20.2994\n",
      "Epoch [38/100], Training Loss: 4.1342, Validation Loss: 20.1451\n",
      "Epoch [39/100], Training Loss: 4.3585, Validation Loss: 20.1575\n",
      "Epoch [40/100], Training Loss: 4.6453, Validation Loss: 19.8781\n",
      "Epoch [41/100], Training Loss: 6.5895, Validation Loss: 19.9707\n",
      "Epoch [42/100], Training Loss: 3.7829, Validation Loss: 19.7680\n",
      "Epoch [43/100], Training Loss: 4.6545, Validation Loss: 19.5798\n",
      "Epoch [44/100], Training Loss: 4.4147, Validation Loss: 19.5947\n",
      "Epoch [45/100], Training Loss: 2.7948, Validation Loss: 19.4148\n",
      "Epoch [46/100], Training Loss: 5.0031, Validation Loss: 19.3125\n",
      "Epoch [47/100], Training Loss: 4.6281, Validation Loss: 19.2172\n",
      "Epoch [48/100], Training Loss: 3.2012, Validation Loss: 19.1988\n",
      "Epoch [49/100], Training Loss: 3.5379, Validation Loss: 19.0734\n",
      "Epoch [50/100], Training Loss: 5.1187, Validation Loss: 19.0304\n",
      "Epoch [51/100], Training Loss: 3.7402, Validation Loss: 19.0639\n",
      "Epoch [52/100], Training Loss: 4.9423, Validation Loss: 18.9500\n",
      "Epoch [53/100], Training Loss: 3.6216, Validation Loss: 18.8750\n",
      "Epoch [54/100], Training Loss: 2.4133, Validation Loss: 18.7806\n",
      "Epoch [55/100], Training Loss: 4.8490, Validation Loss: 18.6084\n",
      "Epoch [56/100], Training Loss: 4.6281, Validation Loss: 18.6065\n",
      "Epoch [57/100], Training Loss: 3.6758, Validation Loss: 18.5547\n",
      "Epoch [58/100], Training Loss: 3.2316, Validation Loss: 18.6272\n",
      "Epoch [59/100], Training Loss: 2.9997, Validation Loss: 18.4727\n",
      "Epoch [60/100], Training Loss: 3.6778, Validation Loss: 18.4085\n",
      "Epoch [61/100], Training Loss: 4.1713, Validation Loss: 18.3078\n",
      "Epoch [62/100], Training Loss: 3.8128, Validation Loss: 18.2630\n",
      "Epoch [63/100], Training Loss: 2.6071, Validation Loss: 18.2073\n",
      "Epoch [64/100], Training Loss: 3.4713, Validation Loss: 18.1232\n",
      "Epoch [65/100], Training Loss: 4.0888, Validation Loss: 18.1347\n",
      "Epoch [66/100], Training Loss: 5.1662, Validation Loss: 18.0298\n",
      "Epoch [67/100], Training Loss: 4.6520, Validation Loss: 17.9555\n",
      "Epoch [68/100], Training Loss: 3.8657, Validation Loss: 18.1127\n",
      "Epoch [69/100], Training Loss: 3.9891, Validation Loss: 17.9320\n",
      "Epoch [70/100], Training Loss: 5.9497, Validation Loss: 17.8806\n",
      "Epoch [71/100], Training Loss: 4.1909, Validation Loss: 17.7410\n",
      "Epoch [72/100], Training Loss: 3.1206, Validation Loss: 17.7386\n",
      "Epoch [73/100], Training Loss: 4.8222, Validation Loss: 17.6499\n",
      "Epoch [74/100], Training Loss: 2.7041, Validation Loss: 17.6748\n",
      "Epoch [75/100], Training Loss: 3.7715, Validation Loss: 17.7151\n",
      "Epoch [76/100], Training Loss: 4.7562, Validation Loss: 17.6617\n",
      "Epoch [77/100], Training Loss: 3.5168, Validation Loss: 17.5994\n",
      "Epoch [78/100], Training Loss: 3.8857, Validation Loss: 17.5530\n",
      "Epoch [79/100], Training Loss: 3.5955, Validation Loss: 17.5649\n",
      "Epoch [80/100], Training Loss: 3.8161, Validation Loss: 17.5137\n",
      "Epoch [81/100], Training Loss: 4.2504, Validation Loss: 17.4592\n",
      "Epoch [82/100], Training Loss: 4.9834, Validation Loss: 17.4881\n",
      "Epoch [83/100], Training Loss: 3.6260, Validation Loss: 17.4228\n",
      "Epoch [84/100], Training Loss: 3.6158, Validation Loss: 17.4162\n",
      "Epoch [85/100], Training Loss: 4.5848, Validation Loss: 17.2947\n",
      "Epoch [86/100], Training Loss: 2.8232, Validation Loss: 17.3616\n",
      "Epoch [87/100], Training Loss: 3.1577, Validation Loss: 17.3677\n",
      "Epoch [88/100], Training Loss: 2.2780, Validation Loss: 17.2935\n",
      "Epoch [89/100], Training Loss: 2.7116, Validation Loss: 17.2902\n",
      "Epoch [90/100], Training Loss: 2.8474, Validation Loss: 17.2403\n",
      "Epoch [91/100], Training Loss: 5.9368, Validation Loss: 17.1200\n",
      "Epoch [92/100], Training Loss: 3.2837, Validation Loss: 17.2624\n",
      "Epoch [93/100], Training Loss: 3.3716, Validation Loss: 17.1036\n",
      "Epoch [94/100], Training Loss: 2.9507, Validation Loss: 17.1513\n",
      "Epoch [95/100], Training Loss: 3.1098, Validation Loss: 17.1480\n",
      "Epoch [96/100], Training Loss: 3.6759, Validation Loss: 17.0897\n",
      "Epoch [97/100], Training Loss: 3.0088, Validation Loss: 17.1167\n",
      "Epoch [98/100], Training Loss: 3.9457, Validation Loss: 17.1394\n",
      "Epoch [99/100], Training Loss: 6.0530, Validation Loss: 17.1026\n",
      "Epoch [100/100], Training Loss: 4.0083, Validation Loss: 17.0553\n",
      "F1-Score: 0.9722, Optimal Threshold: 11.5520\n"
     ]
    }
   ],
   "source": [
    "test_ratio = 0.2\n",
    "threshold_ratio = 0.1\n",
    "input_size = 39  \n",
    "hidden_size = 128\n",
    "latent_size = 10\n",
    "learning_rate = 1e-5\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "precision = {}\n",
    "recall = {}\n",
    "average_precision = {}\n",
    "\n",
    "batch_size = 16 \n",
    "\n",
    "for trueUser in users:\n",
    "    dataset = balabitAnalyser.createTrainingDataWithLabel(trueUser)\n",
    "    neuralDataCreator = NeuralDataCreator(dataset)\n",
    "    x_training, y_training, x_validation, y_validation, x_threshold_positive, x_threshold_negative, y_threshold, x_test, y_test = neuralDataCreator.create_data(test_ratio, threshold_ratio)\n",
    "\n",
    "\n",
    "    training_dataset, validation_dataset, treshold_dataset_positive, treshold_dataset_negative , test_dataset = neuralDataCreator.create_datasets(x_training, x_validation , x_threshold_positive, x_threshold_negative, x_test)\n",
    "\n",
    "## CREATING DATALOADERS ##\n",
    "\n",
    "    training_loader = DataLoader(training_dataset, batch_size=16, shuffle=True)\n",
    "    validation_loader = DataLoader(validation_dataset, batch_size=16, shuffle=False)\n",
    "    threshold_loader_positive = DataLoader(treshold_dataset_positive, batch_size=batch_size, shuffle=False)\n",
    "    threshold_loader_negative = DataLoader(treshold_dataset_negative, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = VAE(input_size, hidden_size, latent_size, learning_rate)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    weight = 0.5\n",
    "\n",
    "    # Optimizer\n",
    "    num_epochs = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in training_loader:\n",
    "            model.train()  # Set the model to training mode\n",
    "            kl_weight = min(epoch / (num_epochs/3), 1.0)\n",
    "            # kl_weight = 1\n",
    "\n",
    "            x = batch.to(device)\n",
    "            x = x.view(-1, input_size)\n",
    "\n",
    "            # Forward pass\n",
    "            loss = model.train_step(x, weight, kl_weight)\n",
    "\n",
    "    \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            total_validation_loss = 0.0\n",
    "            num_validation_batches = 0\n",
    "\n",
    "            for batch in validation_loader:\n",
    "                x_val = batch.to(device)\n",
    "                x_val = x_val.view(-1, input_size)\n",
    "                reconstruction_val, mu_val, log_var_val = model(x_val)\n",
    "                validation_loss = model.compute_loss(reconstruction_val, x_val, mu_val, log_var_val, weight, kl_weight)\n",
    "\n",
    "                total_validation_loss += validation_loss.item()\n",
    "                num_validation_batches += 1\n",
    "\n",
    "        average_validation_loss = total_validation_loss / num_validation_batches\n",
    "\n",
    "        # Print the loss at the end of each epoch\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss:.4f}, Validation Loss: {average_validation_loss:.4f}')\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    artificial_labels  = []\n",
    "    validation_losses = []\n",
    "    reconstruction_losses_positive = []\n",
    "    reconstruction_losses_negative = []\n",
    "    with torch.no_grad():\n",
    "        total_validation_loss = 0.0\n",
    "        num_validation_batches = 0\n",
    "\n",
    "        # for batch in threshold_loader_positive:\n",
    "        #     x_val = batch.to(device)\n",
    "        #     x_val = x_val.view(-1, input_size)\n",
    "        #     reconstruction_val, mu_val, log_var_val = model(x_val)\n",
    "        #     validation_loss = model.compute_loss(reconstruction_val, x_val, mu_val, log_var_val, weight, kl_weight)\n",
    "        #     validation_losses.append(validation_loss.item())\n",
    "        #     total_validation_loss += validation_loss.item()\n",
    "        #     num_validation_batches += 1\n",
    "        #     artificial_labels.append(0)\n",
    "\n",
    "        # average_validation_loss = total_validation_loss / num_validation_batches\n",
    "\n",
    "    \n",
    "        for batch in threshold_loader_negative:\n",
    "                x_val = batch.to(device)\n",
    "                x_val = x_val.view(-1, input_size)\n",
    "                reconstruction_val, mu_val, log_var_val = model(x_val)\n",
    "                validation_loss = model.compute_loss(reconstruction_val, x_val, mu_val, log_var_val, weight, kl_weight)\n",
    "                validation_losses.append(validation_loss.item())\n",
    "                total_validation_loss += validation_loss.item()\n",
    "                num_validation_batches += 1\n",
    "                artificial_labels.append(1)\n",
    "                reconstruction_losses_negative.append(validation_loss.item())\n",
    "\n",
    "        for batch in threshold_loader_positive:\n",
    "            x_val = batch.to(device)\n",
    "            x_val = x_val.view(-1, input_size)\n",
    "            reconstruction_val, mu_val, log_var_val = model(x_val)\n",
    "            validation_loss = model.compute_loss(reconstruction_val, x_val, mu_val, log_var_val, weight, kl_weight)\n",
    "            validation_losses.append(validation_loss.item())\n",
    "            total_validation_loss += validation_loss.item()\n",
    "            num_validation_batches += 1\n",
    "            artificial_labels.append(0)\n",
    "            reconstruction_losses_positive.append(validation_loss.item())\n",
    "\n",
    "\n",
    "        average_validation_loss = total_validation_loss / num_validation_batches\n",
    "\n",
    "        num_samples = num_validation_batches\n",
    "\n",
    "\n",
    "\n",
    "    thresholds = np.linspace(min(validation_losses), max(validation_losses), 100)\n",
    "    f1_scores = [f1_score(artificial_labels, validation_losses > t) for t in thresholds]\n",
    "    # f1_scores = [f1_score(y_artificial_lab, validation_losses > t) for t in thresholds]\n",
    "\n",
    "    optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "\n",
    "\n",
    "    print(f'F1-Score: {max(f1_scores):.4f}, Optimal Threshold: {optimal_threshold:.4f}')\n",
    "    fpr[trueUser], tpr[trueUser], threshold = roc_curve(artificial_labels, validation_losses)\n",
    "    roc_auc[trueUser] = auc(fpr[trueUser], tpr[trueUser])\n",
    "\n",
    "\n",
    "\n",
    "    precision[trueUser], recall[trueUser], _ = precision_recall_curve(artificial_labels, validation_losses)\n",
    "\n",
    "# Calculate the area under the precision-recall curve (AUC-PR)\n",
    "    average_precision[trueUser] = auc(recall[trueUser], precision[trueUser])\n",
    "    ### OPTIMAL THRESHOLD ROC AUC ##\n",
    "    optimal_threshold_index_auc = np.argmax(tpr[trueUser] - fpr[trueUser])\n",
    "    optimal_threshold_ROC = threshold[optimal_threshold_index_auc]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    validation_losses = []\n",
    "    iterator = 0\n",
    "    y_label = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            x_val = batch.to(device)\n",
    "            x_val = x_val.view(-1, input_size)\n",
    "            reconstruction_val, mu_val, log_var_val = model(x_val)\n",
    "            validation_loss = model.compute_loss(reconstruction_val, x_val, mu_val, log_var_val, weight, kl_weight)\n",
    "            validation_losses.append(validation_loss.item())\n",
    "            y_label.append(y_test[iterator*batch_size])\n",
    "            iterator+=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    predictions = (validation_losses < optimal_threshold_ROC).astype(int)\n",
    "\n",
    "    y_pred = (validation_losses < optimal_threshold_ROC).astype(int)\n",
    "\n",
    "    # Confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_label, y_pred)\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy_final[trueUser] = accuracy_score(y_label, y_pred)\n",
    "\n",
    "    # Precision\n",
    "    precision_final[trueUser] = precision_score(y_label, y_pred)\n",
    "\n",
    "    # Recall\n",
    "    recall_final[trueUser] = recall_score(y_label, y_pred)\n",
    "\n",
    "    # F1 Score\n",
    "    f1_final[trueUser] = f1_score(y_label, y_pred)\n",
    "\n",
    "    # Matthews correlation coefficient\n",
    "    mcc_final[trueUser] = matthews_corrcoef(y_label, y_pred)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING ON DATA ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_path = f'wykresy\\\\VAEBalabit_balanced{batch_size}ROC'\n",
    "pr_path = f'wykresy\\\\VAEBalabit_balanced{batch_size}PR'\n",
    "plotROCs(fpr, tpr, roc_auc, users,False, True, roc_path)\n",
    "plot_precisions_recalls(precision, recall, average_precision, True, pr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{7: 0.963302752293578,\n",
       " 9: 0.9402985074626866,\n",
       " 12: 0.838150289017341,\n",
       " 15: 0.7909090909090909,\n",
       " 16: 0.8562874251497006,\n",
       " 20: 0.7375,\n",
       " 21: 0.9101123595505618,\n",
       " 23: 0.6823529411764706,\n",
       " 29: 0.719626168224299,\n",
       " 35: 0.9583333333333334}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{7: 0.9473684210526315,\n",
       " 9: 0.8947368421052632,\n",
       " 12: 0.8734177215189873,\n",
       " 15: 0.82,\n",
       " 16: 0.8658536585365854,\n",
       " 20: 0.9523809523809523,\n",
       " 21: 0.9512195121951219,\n",
       " 23: 0.75,\n",
       " 29: 0.7222222222222222,\n",
       " 35: 0.9230769230769231}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{7: 0.9818181818181818,\n",
       " 9: 1.0,\n",
       " 12: 0.7931034482758621,\n",
       " 15: 0.7454545454545455,\n",
       " 16: 0.8452380952380952,\n",
       " 20: 0.5,\n",
       " 21: 0.8666666666666667,\n",
       " 23: 0.5581395348837209,\n",
       " 29: 0.7222222222222222,\n",
       " 35: 1.0}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{7: 0.9642857142857142,\n",
       " 9: 0.9444444444444444,\n",
       " 12: 0.8313253012048193,\n",
       " 15: 0.780952380952381,\n",
       " 16: 0.8554216867469879,\n",
       " 20: 0.6557377049180327,\n",
       " 21: 0.9069767441860465,\n",
       " 23: 0.6399999999999999,\n",
       " 29: 0.7222222222222222,\n",
       " 35: 0.9600000000000001}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{7: 0.9271996650720626,\n",
       " 9: 0.8867265032393299,\n",
       " 12: 0.6793715760320801,\n",
       " 15: 0.5842373946721772,\n",
       " 16: 0.7128102210768651,\n",
       " 20: 0.5397814402407793,\n",
       " 21: 0.8237120116864876,\n",
       " 23: 0.3793990878450622,\n",
       " 29: 0.4392033542976939,\n",
       " 35: 0.9198662110077999}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcc_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{7: 0.9821487603305785,\n",
       " 9: 0.9316608996539791,\n",
       " 12: 0.9553441669969612,\n",
       " 15: 0.9047933884297521,\n",
       " 16: 0.9384920634920635,\n",
       " 20: 0.9975,\n",
       " 21: 0.9520987654320987,\n",
       " 23: 0.6976744186046512,\n",
       " 29: 0.8415637860082305,\n",
       " 35: 0.9544753086419753}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
